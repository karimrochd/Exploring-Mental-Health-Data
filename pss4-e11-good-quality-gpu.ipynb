{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21a842a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-11-18T17:09:25.752325Z",
     "iopub.status.busy": "2024-11-18T17:09:25.751982Z",
     "iopub.status.idle": "2024-11-18T17:10:18.051020Z",
     "shell.execute_reply": "2024-11-18T17:10:18.049880Z"
    },
    "papermill": {
     "duration": 52.30612,
     "end_time": "2024-11-18T17:10:18.052986",
     "exception": false,
     "start_time": "2024-11-18T17:09:25.746866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray==2.10.0\r\n",
      "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (8.1.7)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (3.15.1)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (4.22.0)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.0.8)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (21.3)\r\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (3.20.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.3.1)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (1.4.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.10.0) (2.32.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.10.0) (0.18.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.10.0) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.10.0) (2024.8.30)\r\n",
      "Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ray\r\n",
      "  Attempting uninstall: ray\r\n",
      "    Found existing installation: ray 2.24.0\r\n",
      "    Uninstalling ray-2.24.0:\r\n",
      "      Successfully uninstalled ray-2.24.0\r\n",
      "Successfully installed ray-2.10.0\r\n",
      "Collecting autogluon.tabular\r\n",
      "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular) (1.26.4)\r\n",
      "Collecting scipy<1.13,>=1.5.4 (from autogluon.tabular)\r\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular) (2.2.2)\r\n",
      "Collecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.tabular)\r\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular) (3.3)\r\n",
      "Collecting autogluon.core==1.1.1 (from autogluon.tabular)\r\n",
      "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting autogluon.features==1.1.1 (from autogluon.tabular)\r\n",
      "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.tabular) (4.66.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.tabular) (2.32.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.tabular) (3.7.5)\r\n",
      "Requirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.tabular) (1.26.100)\r\n",
      "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.tabular)\r\n",
      "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (5.9.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (70.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (3.5.0)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular) (0.6.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->autogluon.tabular) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (2024.8.30)\r\n",
      "Downloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scipy, scikit-learn, botocore, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.14.1\r\n",
      "    Uninstalling scipy-1.14.1:\r\n",
      "      Successfully uninstalled scipy-1.14.1\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.35.23\r\n",
      "    Uninstalling botocore-1.35.23:\r\n",
      "      Successfully uninstalled botocore-1.35.23\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "aiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.tabular-1.1.1 botocore-1.29.165 scikit-learn-1.4.0 scipy-1.12.0\r\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\r\n",
      "Collecting ipywidgets\r\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\r\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\r\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\r\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\r\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\r\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\r\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\r\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\r\n",
      "  Attempting uninstall: widgetsnbextension\r\n",
      "    Found existing installation: widgetsnbextension 3.6.9\r\n",
      "    Uninstalling widgetsnbextension-3.6.9:\r\n",
      "      Successfully uninstalled widgetsnbextension-3.6.9\r\n",
      "  Attempting uninstall: jupyterlab-widgets\r\n",
      "    Found existing installation: jupyterlab_widgets 3.0.11\r\n",
      "    Uninstalling jupyterlab_widgets-3.0.11:\r\n",
      "      Successfully uninstalled jupyterlab_widgets-3.0.11\r\n",
      "  Attempting uninstall: ipywidgets\r\n",
      "    Found existing installation: ipywidgets 7.7.1\r\n",
      "    Uninstalling ipywidgets-7.7.1:\r\n",
      "      Successfully uninstalled ipywidgets-7.7.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ray==2.10.0\n",
    "!pip install autogluon.tabular\n",
    "!pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2498480b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:18.070729Z",
     "iopub.status.busy": "2024-11-18T17:10:18.070453Z",
     "iopub.status.idle": "2024-11-18T17:10:19.160177Z",
     "shell.execute_reply": "2024-11-18T17:10:19.159358Z"
    },
    "papermill": {
     "duration": 1.100169,
     "end_time": "2024-11-18T17:10:19.162031",
     "exception": false,
     "start_time": "2024-11-18T17:10:18.061862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Working Professional or Student</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaradhya</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Chef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BHM</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vivan</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>LLB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rhea</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      Name  Gender   Age           City Working Professional or Student  \\\n",
       "0   0  Aaradhya  Female  49.0       Ludhiana            Working Professional   \n",
       "1   1     Vivan    Male  26.0       Varanasi            Working Professional   \n",
       "2   2    Yuvraj    Male  33.0  Visakhapatnam                         Student   \n",
       "3   3    Yuvraj    Male  22.0         Mumbai            Working Professional   \n",
       "4   4      Rhea  Female  30.0         Kanpur            Working Professional   \n",
       "\n",
       "         Profession  Academic Pressure  Work Pressure  CGPA  \\\n",
       "0              Chef                NaN            5.0   NaN   \n",
       "1           Teacher                NaN            4.0   NaN   \n",
       "2               NaN                5.0            NaN  8.97   \n",
       "3           Teacher                NaN            5.0   NaN   \n",
       "4  Business Analyst                NaN            1.0   NaN   \n",
       "\n",
       "   Study Satisfaction  Job Satisfaction     Sleep Duration Dietary Habits  \\\n",
       "0                 NaN               2.0  More than 8 hours        Healthy   \n",
       "1                 NaN               3.0  Less than 5 hours      Unhealthy   \n",
       "2                 2.0               NaN          5-6 hours        Healthy   \n",
       "3                 NaN               1.0  Less than 5 hours       Moderate   \n",
       "4                 NaN               1.0          5-6 hours      Unhealthy   \n",
       "\n",
       "    Degree Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "0      BHM                                    No               1.0   \n",
       "1      LLB                                   Yes               7.0   \n",
       "2  B.Pharm                                   Yes               3.0   \n",
       "3      BBA                                   Yes              10.0   \n",
       "4      BBA                                   Yes               9.0   \n",
       "\n",
       "   Financial Stress Family History of Mental Illness  Depression  \n",
       "0               2.0                               No           0  \n",
       "1               3.0                               No           1  \n",
       "2               1.0                               No           1  \n",
       "3               1.0                              Yes           1  \n",
       "4               4.0                              Yes           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('/kaggle/input/playground-series-s4e11/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850b3c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.179552Z",
     "iopub.status.busy": "2024-11-18T17:10:19.179251Z",
     "iopub.status.idle": "2024-11-18T17:10:19.461179Z",
     "shell.execute_reply": "2024-11-18T17:10:19.460365Z"
    },
    "papermill": {
     "duration": 0.292637,
     "end_time": "2024-11-18T17:10:19.463176",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.170539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Working Professional or Student</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140700</td>\n",
       "      <td>Shivam</td>\n",
       "      <td>Male</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Judge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>LLB</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140701</td>\n",
       "      <td>Sanya</td>\n",
       "      <td>Female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Educational Consultant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140702</td>\n",
       "      <td>Yash</td>\n",
       "      <td>Male</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Arch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140703</td>\n",
       "      <td>Nalini</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140704</td>\n",
       "      <td>Shaurya</td>\n",
       "      <td>Male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Kalyan</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     Name  Gender   Age           City  \\\n",
       "0  140700   Shivam    Male  53.0  Visakhapatnam   \n",
       "1  140701    Sanya  Female  58.0        Kolkata   \n",
       "2  140702     Yash    Male  53.0         Jaipur   \n",
       "3  140703   Nalini  Female  23.0         Rajkot   \n",
       "4  140704  Shaurya    Male  47.0         Kalyan   \n",
       "\n",
       "  Working Professional or Student              Profession  Academic Pressure  \\\n",
       "0            Working Professional                   Judge                NaN   \n",
       "1            Working Professional  Educational Consultant                NaN   \n",
       "2            Working Professional                 Teacher                NaN   \n",
       "3                         Student                     NaN                5.0   \n",
       "4            Working Professional                 Teacher                NaN   \n",
       "\n",
       "   Work Pressure  CGPA  Study Satisfaction  Job Satisfaction  \\\n",
       "0            2.0   NaN                 NaN               5.0   \n",
       "1            2.0   NaN                 NaN               4.0   \n",
       "2            4.0   NaN                 NaN               1.0   \n",
       "3            NaN  6.84                 1.0               NaN   \n",
       "4            5.0   NaN                 NaN               5.0   \n",
       "\n",
       "      Sleep Duration Dietary Habits  Degree  \\\n",
       "0  Less than 5 hours       Moderate     LLB   \n",
       "1  Less than 5 hours       Moderate    B.Ed   \n",
       "2          7-8 hours       Moderate  B.Arch   \n",
       "3  More than 8 hours       Moderate     BSc   \n",
       "4          7-8 hours       Moderate     BCA   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours  Financial Stress  \\\n",
       "0                                    No               9.0               3.0   \n",
       "1                                    No               6.0               4.0   \n",
       "2                                   Yes              12.0               4.0   \n",
       "3                                   Yes              10.0               4.0   \n",
       "4                                   Yes               3.0               4.0   \n",
       "\n",
       "  Family History of Mental Illness  \n",
       "0                              Yes  \n",
       "1                               No  \n",
       "2                               No  \n",
       "3                               No  \n",
       "4                               No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('/kaggle/input/playground-series-s4e11/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c6f7bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.480211Z",
     "iopub.status.busy": "2024-11-18T17:10:19.479941Z",
     "iopub.status.idle": "2024-11-18T17:10:19.558145Z",
     "shell.execute_reply": "2024-11-18T17:10:19.557167Z"
    },
    "papermill": {
     "duration": 0.088451,
     "end_time": "2024-11-18T17:10:19.559823",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.471372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140700 entries, 0 to 140699\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   id                                     140700 non-null  int64  \n",
      " 1   Name                                   140700 non-null  object \n",
      " 2   Gender                                 140700 non-null  object \n",
      " 3   Age                                    140700 non-null  float64\n",
      " 4   City                                   140700 non-null  object \n",
      " 5   Working Professional or Student        140700 non-null  object \n",
      " 6   Profession                             104070 non-null  object \n",
      " 7   Academic Pressure                      27897 non-null   float64\n",
      " 8   Work Pressure                          112782 non-null  float64\n",
      " 9   CGPA                                   27898 non-null   float64\n",
      " 10  Study Satisfaction                     27897 non-null   float64\n",
      " 11  Job Satisfaction                       112790 non-null  float64\n",
      " 12  Sleep Duration                         140700 non-null  object \n",
      " 13  Dietary Habits                         140696 non-null  object \n",
      " 14  Degree                                 140698 non-null  object \n",
      " 15  Have you ever had suicidal thoughts ?  140700 non-null  object \n",
      " 16  Work/Study Hours                       140700 non-null  float64\n",
      " 17  Financial Stress                       140696 non-null  float64\n",
      " 18  Family History of Mental Illness       140700 non-null  object \n",
      " 19  Depression                             140700 non-null  int64  \n",
      "dtypes: float64(8), int64(2), object(10)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7fd385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.576928Z",
     "iopub.status.busy": "2024-11-18T17:10:19.576682Z",
     "iopub.status.idle": "2024-11-18T17:10:19.661860Z",
     "shell.execute_reply": "2024-11-18T17:10:19.661174Z"
    },
    "papermill": {
     "duration": 0.0954,
     "end_time": "2024-11-18T17:10:19.663372",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.567972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       140700\n",
       "Name                                        422\n",
       "CGPA                                        331\n",
       "Degree                                      115\n",
       "City                                         98\n",
       "Profession                                   64\n",
       "Age                                          43\n",
       "Sleep Duration                               36\n",
       "Dietary Habits                               23\n",
       "Work/Study Hours                             13\n",
       "Financial Stress                              5\n",
       "Academic Pressure                             5\n",
       "Work Pressure                                 5\n",
       "Job Satisfaction                              5\n",
       "Study Satisfaction                            5\n",
       "Gender                                        2\n",
       "Working Professional or Student               2\n",
       "Have you ever had suicidal thoughts ?         2\n",
       "Family History of Mental Illness              2\n",
       "Depression                                    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47c2b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.680711Z",
     "iopub.status.busy": "2024-11-18T17:10:19.680192Z",
     "iopub.status.idle": "2024-11-18T17:10:19.706417Z",
     "shell.execute_reply": "2024-11-18T17:10:19.705616Z"
    },
    "papermill": {
     "duration": 0.036521,
     "end_time": "2024-11-18T17:10:19.707890",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.671369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Working Professional or Student</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaradhya</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Chef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BHM</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vivan</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>LLB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rhea</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Gender   Age           City Working Professional or Student  \\\n",
       "0  Aaradhya  Female  49.0       Ludhiana            Working Professional   \n",
       "1     Vivan    Male  26.0       Varanasi            Working Professional   \n",
       "2    Yuvraj    Male  33.0  Visakhapatnam                         Student   \n",
       "3    Yuvraj    Male  22.0         Mumbai            Working Professional   \n",
       "4      Rhea  Female  30.0         Kanpur            Working Professional   \n",
       "\n",
       "         Profession  Academic Pressure  Work Pressure  CGPA  \\\n",
       "0              Chef                NaN            5.0   NaN   \n",
       "1           Teacher                NaN            4.0   NaN   \n",
       "2               NaN                5.0            NaN  8.97   \n",
       "3           Teacher                NaN            5.0   NaN   \n",
       "4  Business Analyst                NaN            1.0   NaN   \n",
       "\n",
       "   Study Satisfaction  Job Satisfaction     Sleep Duration Dietary Habits  \\\n",
       "0                 NaN               2.0  More than 8 hours        Healthy   \n",
       "1                 NaN               3.0  Less than 5 hours      Unhealthy   \n",
       "2                 2.0               NaN          5-6 hours        Healthy   \n",
       "3                 NaN               1.0  Less than 5 hours       Moderate   \n",
       "4                 NaN               1.0          5-6 hours      Unhealthy   \n",
       "\n",
       "    Degree Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "0      BHM                                    No               1.0   \n",
       "1      LLB                                   Yes               7.0   \n",
       "2  B.Pharm                                   Yes               3.0   \n",
       "3      BBA                                   Yes              10.0   \n",
       "4      BBA                                   Yes               9.0   \n",
       "\n",
       "   Financial Stress Family History of Mental Illness  Depression  \n",
       "0               2.0                               No           0  \n",
       "1               3.0                               No           1  \n",
       "2               1.0                               No           1  \n",
       "3               1.0                              Yes           1  \n",
       "4               4.0                              Yes           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.drop(['id'],axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c772cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.724938Z",
     "iopub.status.busy": "2024-11-18T17:10:19.724695Z",
     "iopub.status.idle": "2024-11-18T17:10:19.745743Z",
     "shell.execute_reply": "2024-11-18T17:10:19.745015Z"
    },
    "papermill": {
     "duration": 0.031205,
     "end_time": "2024-11-18T17:10:19.747238",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.716033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Working Professional or Student</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shivam</td>\n",
       "      <td>Male</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Judge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>LLB</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanya</td>\n",
       "      <td>Female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Educational Consultant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yash</td>\n",
       "      <td>Male</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Arch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nalini</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaurya</td>\n",
       "      <td>Male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Kalyan</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7-8 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Gender   Age           City Working Professional or Student  \\\n",
       "0   Shivam    Male  53.0  Visakhapatnam            Working Professional   \n",
       "1    Sanya  Female  58.0        Kolkata            Working Professional   \n",
       "2     Yash    Male  53.0         Jaipur            Working Professional   \n",
       "3   Nalini  Female  23.0         Rajkot                         Student   \n",
       "4  Shaurya    Male  47.0         Kalyan            Working Professional   \n",
       "\n",
       "               Profession  Academic Pressure  Work Pressure  CGPA  \\\n",
       "0                   Judge                NaN            2.0   NaN   \n",
       "1  Educational Consultant                NaN            2.0   NaN   \n",
       "2                 Teacher                NaN            4.0   NaN   \n",
       "3                     NaN                5.0            NaN  6.84   \n",
       "4                 Teacher                NaN            5.0   NaN   \n",
       "\n",
       "   Study Satisfaction  Job Satisfaction     Sleep Duration Dietary Habits  \\\n",
       "0                 NaN               5.0  Less than 5 hours       Moderate   \n",
       "1                 NaN               4.0  Less than 5 hours       Moderate   \n",
       "2                 NaN               1.0          7-8 hours       Moderate   \n",
       "3                 1.0               NaN  More than 8 hours       Moderate   \n",
       "4                 NaN               5.0          7-8 hours       Moderate   \n",
       "\n",
       "   Degree Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "0     LLB                                    No               9.0   \n",
       "1    B.Ed                                    No               6.0   \n",
       "2  B.Arch                                   Yes              12.0   \n",
       "3     BSc                                   Yes              10.0   \n",
       "4     BCA                                   Yes               3.0   \n",
       "\n",
       "   Financial Stress Family History of Mental Illness  \n",
       "0               3.0                              Yes  \n",
       "1               4.0                               No  \n",
       "2               4.0                               No  \n",
       "3               4.0                               No  \n",
       "4               4.0                               No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=test.drop(['id'],axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28267d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.764919Z",
     "iopub.status.busy": "2024-11-18T17:10:19.764680Z",
     "iopub.status.idle": "2024-11-18T17:10:19.828410Z",
     "shell.execute_reply": "2024-11-18T17:10:19.827739Z"
    },
    "papermill": {
     "duration": 0.074399,
     "end_time": "2024-11-18T17:10:19.829907",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.755508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                          0\n",
       "Gender                                        0\n",
       "Age                                           0\n",
       "City                                          0\n",
       "Working Professional or Student               0\n",
       "Profession                                36630\n",
       "Academic Pressure                        112803\n",
       "Work Pressure                             27918\n",
       "CGPA                                     112802\n",
       "Study Satisfaction                       112803\n",
       "Job Satisfaction                          27910\n",
       "Sleep Duration                                0\n",
       "Dietary Habits                                4\n",
       "Degree                                        2\n",
       "Have you ever had suicidal thoughts ?         0\n",
       "Work/Study Hours                              0\n",
       "Financial Stress                              4\n",
       "Family History of Mental Illness              0\n",
       "Depression                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f858c455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.848308Z",
     "iopub.status.busy": "2024-11-18T17:10:19.847869Z",
     "iopub.status.idle": "2024-11-18T17:10:19.877444Z",
     "shell.execute_reply": "2024-11-18T17:10:19.876713Z"
    },
    "papermill": {
     "duration": 0.040462,
     "end_time": "2024-11-18T17:10:19.879085",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.838623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>Working Professional or Student</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaradhya</td>\n",
       "      <td>Female</td>\n",
       "      <td>Ludhiana</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Chef</td>\n",
       "      <td>More than 8 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BHM</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vivan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>LLB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yuvraj</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Less than 5 hours</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rhea</td>\n",
       "      <td>Female</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>Working Professional</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>5-6 hours</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>BBA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Gender           City Working Professional or Student  \\\n",
       "0  Aaradhya  Female       Ludhiana            Working Professional   \n",
       "1     Vivan    Male       Varanasi            Working Professional   \n",
       "2    Yuvraj    Male  Visakhapatnam                         Student   \n",
       "3    Yuvraj    Male         Mumbai            Working Professional   \n",
       "4      Rhea  Female         Kanpur            Working Professional   \n",
       "\n",
       "         Profession     Sleep Duration Dietary Habits   Degree  \\\n",
       "0              Chef  More than 8 hours        Healthy      BHM   \n",
       "1           Teacher  Less than 5 hours      Unhealthy      LLB   \n",
       "2               NaN          5-6 hours        Healthy  B.Pharm   \n",
       "3           Teacher  Less than 5 hours       Moderate      BBA   \n",
       "4  Business Analyst          5-6 hours      Unhealthy      BBA   \n",
       "\n",
       "  Have you ever had suicidal thoughts ? Family History of Mental Illness  \n",
       "0                                    No                               No  \n",
       "1                                   Yes                               No  \n",
       "2                                   Yes                               No  \n",
       "3                                   Yes                              Yes  \n",
       "4                                   Yes                              Yes  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[test.select_dtypes(include=['object']).columns.tolist()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99116b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.897899Z",
     "iopub.status.busy": "2024-11-18T17:10:19.897651Z",
     "iopub.status.idle": "2024-11-18T17:10:19.974590Z",
     "shell.execute_reply": "2024-11-18T17:10:19.973760Z"
    },
    "papermill": {
     "duration": 0.087876,
     "end_time": "2024-11-18T17:10:19.976110",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.888234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140700.000000</td>\n",
       "      <td>27897.000000</td>\n",
       "      <td>112782.000000</td>\n",
       "      <td>27898.000000</td>\n",
       "      <td>27897.000000</td>\n",
       "      <td>112790.000000</td>\n",
       "      <td>140700.000000</td>\n",
       "      <td>140696.000000</td>\n",
       "      <td>140700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.388621</td>\n",
       "      <td>3.142273</td>\n",
       "      <td>2.998998</td>\n",
       "      <td>7.658636</td>\n",
       "      <td>2.944940</td>\n",
       "      <td>2.974404</td>\n",
       "      <td>6.252679</td>\n",
       "      <td>2.988983</td>\n",
       "      <td>0.181713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.384099</td>\n",
       "      <td>1.380457</td>\n",
       "      <td>1.405771</td>\n",
       "      <td>1.464466</td>\n",
       "      <td>1.360197</td>\n",
       "      <td>1.416078</td>\n",
       "      <td>3.853615</td>\n",
       "      <td>1.413633</td>\n",
       "      <td>0.385609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.030000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Academic Pressure  Work Pressure          CGPA  \\\n",
       "count  140700.000000       27897.000000  112782.000000  27898.000000   \n",
       "mean       40.388621           3.142273       2.998998      7.658636   \n",
       "std        12.384099           1.380457       1.405771      1.464466   \n",
       "min        18.000000           1.000000       1.000000      5.030000   \n",
       "25%        29.000000           2.000000       2.000000      6.290000   \n",
       "50%        42.000000           3.000000       3.000000      7.770000   \n",
       "75%        51.000000           4.000000       4.000000      8.920000   \n",
       "max        60.000000           5.000000       5.000000     10.000000   \n",
       "\n",
       "       Study Satisfaction  Job Satisfaction  Work/Study Hours  \\\n",
       "count        27897.000000     112790.000000     140700.000000   \n",
       "mean             2.944940          2.974404          6.252679   \n",
       "std              1.360197          1.416078          3.853615   \n",
       "min              1.000000          1.000000          0.000000   \n",
       "25%              2.000000          2.000000          3.000000   \n",
       "50%              3.000000          3.000000          6.000000   \n",
       "75%              4.000000          4.000000         10.000000   \n",
       "max              5.000000          5.000000         12.000000   \n",
       "\n",
       "       Financial Stress     Depression  \n",
       "count     140696.000000  140700.000000  \n",
       "mean           2.988983       0.181713  \n",
       "std            1.413633       0.385609  \n",
       "min            1.000000       0.000000  \n",
       "25%            2.000000       0.000000  \n",
       "50%            3.000000       0.000000  \n",
       "75%            4.000000       0.000000  \n",
       "max            5.000000       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e3df88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:19.995079Z",
     "iopub.status.busy": "2024-11-18T17:10:19.994838Z",
     "iopub.status.idle": "2024-11-18T17:10:20.003435Z",
     "shell.execute_reply": "2024-11-18T17:10:20.002811Z"
    },
    "papermill": {
     "duration": 0.019933,
     "end_time": "2024-11-18T17:10:20.004979",
     "exception": false,
     "start_time": "2024-11-18T17:10:19.985046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('object')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d17c243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.023711Z",
     "iopub.status.busy": "2024-11-18T17:10:20.023479Z",
     "iopub.status.idle": "2024-11-18T17:10:20.131440Z",
     "shell.execute_reply": "2024-11-18T17:10:20.130529Z"
    },
    "papermill": {
     "duration": 0.11973,
     "end_time": "2024-11-18T17:10:20.133477",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.013747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 20.40 MB\n",
      "Memory usage after optimization is: 13.02 MB\n",
      "Decreased by 36.2%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140700 entries, 0 to 140699\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   Name                                   140700 non-null  object \n",
      " 1   Gender                                 140700 non-null  object \n",
      " 2   Age                                    140700 non-null  float16\n",
      " 3   City                                   140700 non-null  object \n",
      " 4   Working Professional or Student        140700 non-null  object \n",
      " 5   Profession                             104070 non-null  object \n",
      " 6   Academic Pressure                      27897 non-null   float16\n",
      " 7   Work Pressure                          112782 non-null  float16\n",
      " 8   CGPA                                   27898 non-null   float16\n",
      " 9   Study Satisfaction                     27897 non-null   float16\n",
      " 10  Job Satisfaction                       112790 non-null  float16\n",
      " 11  Sleep Duration                         140700 non-null  object \n",
      " 12  Dietary Habits                         140696 non-null  object \n",
      " 13  Degree                                 140698 non-null  object \n",
      " 14  Have you ever had suicidal thoughts ?  140700 non-null  object \n",
      " 15  Work/Study Hours                       140700 non-null  float16\n",
      " 16  Financial Stress                       140696 non-null  float16\n",
      " 17  Family History of Mental Illness       140700 non-null  object \n",
      " 18  Depression                             140700 non-null  int8   \n",
      "dtypes: float16(8), int8(1), object(10)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = reduce_mem_usage(train)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326967c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.153207Z",
     "iopub.status.busy": "2024-11-18T17:10:20.152941Z",
     "iopub.status.idle": "2024-11-18T17:10:20.233205Z",
     "shell.execute_reply": "2024-11-18T17:10:20.232276Z"
    },
    "papermill": {
     "duration": 0.092015,
     "end_time": "2024-11-18T17:10:20.235177",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.143162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 12.88 MB\n",
      "Memory usage after optimization is: 8.59 MB\n",
      "Decreased by 33.3%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93800 entries, 0 to 93799\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Name                                   93800 non-null  object \n",
      " 1   Gender                                 93800 non-null  object \n",
      " 2   Age                                    93800 non-null  float16\n",
      " 3   City                                   93800 non-null  object \n",
      " 4   Working Professional or Student        93800 non-null  object \n",
      " 5   Profession                             69168 non-null  object \n",
      " 6   Academic Pressure                      18767 non-null  float16\n",
      " 7   Work Pressure                          75022 non-null  float16\n",
      " 8   CGPA                                   18766 non-null  float16\n",
      " 9   Study Satisfaction                     18767 non-null  float16\n",
      " 10  Job Satisfaction                       75026 non-null  float16\n",
      " 11  Sleep Duration                         93800 non-null  object \n",
      " 12  Dietary Habits                         93795 non-null  object \n",
      " 13  Degree                                 93798 non-null  object \n",
      " 14  Have you ever had suicidal thoughts ?  93800 non-null  object \n",
      " 15  Work/Study Hours                       93800 non-null  float16\n",
      " 16  Financial Stress                       93800 non-null  float16\n",
      " 17  Family History of Mental Illness       93800 non-null  object \n",
      "dtypes: float16(8), object(10)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test = reduce_mem_usage(test)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e834cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.254848Z",
     "iopub.status.busy": "2024-11-18T17:10:20.254596Z",
     "iopub.status.idle": "2024-11-18T17:10:20.263431Z",
     "shell.execute_reply": "2024-11-18T17:10:20.262679Z"
    },
    "papermill": {
     "duration": 0.020494,
     "end_time": "2024-11-18T17:10:20.265033",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.244539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Depression\n",
       "0    81.83\n",
       "1    18.17\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train['Depression'].value_counts()*100/len(train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c896a1cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.284675Z",
     "iopub.status.busy": "2024-11-18T17:10:20.284251Z",
     "iopub.status.idle": "2024-11-18T17:10:20.436364Z",
     "shell.execute_reply": "2024-11-18T17:10:20.435280Z"
    },
    "papermill": {
     "duration": 0.163994,
     "end_time": "2024-11-18T17:10:20.438365",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.274371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    140700\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f630e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.459732Z",
     "iopub.status.busy": "2024-11-18T17:10:20.459183Z",
     "iopub.status.idle": "2024-11-18T17:10:20.471631Z",
     "shell.execute_reply": "2024-11-18T17:10:20.470782Z"
    },
    "papermill": {
     "duration": 0.024328,
     "end_time": "2024-11-18T17:10:20.473181",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.448853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    140700.000000\n",
       "mean          0.181713\n",
       "std           0.385609\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           1.000000\n",
       "Name: Depression, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'Depression'\n",
    "train[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26eae2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:20.493573Z",
     "iopub.status.busy": "2024-11-18T17:10:20.492880Z",
     "iopub.status.idle": "2024-11-18T17:10:21.940436Z",
     "shell.execute_reply": "2024-11-18T17:10:21.939760Z"
    },
    "papermill": {
     "duration": 1.45983,
     "end_time": "2024-11-18T17:10:21.942499",
     "exception": false,
     "start_time": "2024-11-18T17:10:20.482669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7474e1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:10:21.964142Z",
     "iopub.status.busy": "2024-11-18T17:10:21.963713Z",
     "iopub.status.idle": "2024-11-18T17:39:31.580403Z",
     "shell.execute_reply": "2024-11-18T17:39:31.579394Z"
    },
    "papermill": {
     "duration": 1749.62962,
     "end_time": "2024-11-18T17:39:31.582448",
     "exception": false,
     "start_time": "2024-11-18T17:10:21.952828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241118_171021\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n",
      "CPU Count:          4\n",
      "GPU Count:          2\n",
      "Memory Avail:       30.10 GB / 31.35 GB (96.0%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'excluded_model_types': ['FASTAI'],\n",
      " 'num_bag_sets': 1,\n",
      " 'refit_full': True,\n",
      " 'save_bag_folds': False,\n",
      " 'set_best_to_refit_full': True,\n",
      " 'verbosity': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': {'num_gpus': 1},\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': ['FASTAI'],\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': True,\n",
      " 'save_bag_folds': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': True,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-18 17:10:27,939\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Beginning AutoGluon training ... Time limit = 8096s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Train Data Rows:    125066\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Train Data Columns: 18\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Label Column:       Depression\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tAvailable Memory:                    30197.12 MB\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTrain Data (Original)  Memory Usage: 77.86 MB (0.3% of available memory)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float16', 'float') :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', 'object') : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('object', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/features/generators/drop_duplicates.py:100: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   feature_sum_map[round(X[feature].sum(), 2)].append(feature)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('float16', 'float') :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('object', 'object') : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('category', 'category') : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('float16', 'float')     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('int8', 'int')          : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.8s = Fit runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTrain Data (Processed) Memory Usage: 3.22 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Data preprocessing and feature engineering runtime = 0.87s ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'NN_TORCH': {},\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'CAT': {},\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'XGB': {},\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'FASTAI': {},\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Excluded models: ['FASTAI'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 10 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5395.23s of the 8094.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=362)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=362)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=363)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=362)\u001b[0m [50]\tvalid_set's binary_logloss: 0.176873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=432)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=363)\u001b[0m 1 warning generated.\u001b[32m [repeated 65x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=432)\u001b[0m [50]\tvalid_set's binary_logloss: 0.173008\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=502)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=502)\u001b[0m [50]\tvalid_set's binary_logloss: 0.175387\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=572)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=572)\u001b[0m [50]\tvalid_set's binary_logloss: 0.174114\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.975\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t35.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t5465.0\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 5354.83s of the 8054.46s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=599)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.11%)\n",
      "\u001b[36m(_ray_fit pid=650)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=650)\u001b[0m [50]\tvalid_set's binary_logloss: 0.174822\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=719)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=719)\u001b[0m [50]\tvalid_set's binary_logloss: 0.172439\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=790)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=792)\u001b[0m [50]\tvalid_set's binary_logloss: 0.175359\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=862)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=862)\u001b[0m [50]\tvalid_set's binary_logloss: 0.172548\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.974\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t28.54s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t6951.0\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 5324.06s of the 8023.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting RandomForestGini_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.53s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_ray_fit pid=864)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9725\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t14.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t38194.0\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5305.27s of the 8004.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.11s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9728\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t15.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t40339.2\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 5286.57s of the 7986.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting CatBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=968)\u001b[0m 0:\tlearn: 0.6557052\ttest: 0.6557717\tbest: 0.6557717 (0)\ttotal: 107ms\tremaining: 427ms\n",
      "\u001b[36m(_ray_fit pid=862)\u001b[0m [250]\tvalid_set's binary_logloss: 0.152225\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m bestTest = 0.5373032009\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m 180:\tlearn: 0.1476540\ttest: 0.1516883\tbest: 0.1516883 (180)\ttotal: 3.98s\tremaining: 1m 40s\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m bestTest = 0.5371065017\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m 400:\tlearn: 0.1428026\ttest: 0.1508563\tbest: 0.1508299 (393)\ttotal: 9.2s\tremaining: 1m 39s\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m bestTest = 0.1496537526\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m bestIteration = 576\n",
      "\u001b[36m(_ray_fit pid=968)\u001b[0m Shrink model to first 577 iterations.\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m 640:\tlearn: 0.1388631\ttest: 0.1503107\tbest: 0.1503107 (640)\ttotal: 14.6s\tremaining: 1m 33s\u001b[32m [repeated 23x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m bestTest = 0.5362522513\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m bestIteration = 4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=967)\u001b[0m Shrink model to first 677 iterations.\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m 0:\tlearn: 0.6089896\ttest: 0.6084607\tbest: 0.6084607 (0)\ttotal: 22.6ms\tremaining: 2m 15s\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m bestTest = 0.5374735635\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m 240:\tlearn: 0.1462254\ttest: 0.1475211\tbest: 0.1475211 (240)\ttotal: 5.25s\tremaining: 2m 5s\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m 340:\tlearn: 0.1430822\ttest: 0.1561905\tbest: 0.1561905 (340)\ttotal: 7.87s\tremaining: 2m 28s\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m 560:\tlearn: 0.1389302\ttest: 0.1556062\tbest: 0.1555628 (530)\ttotal: 13s\tremaining: 2m 23s\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m bestTest = 0.1464496272\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m bestIteration = 678\n",
      "\u001b[36m(_ray_fit pid=1051)\u001b[0m Shrink model to first 679 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m 780:\tlearn: 0.1354708\ttest: 0.1554162\tbest: 0.1554162 (780)\ttotal: 18.3s\tremaining: 2m 20s\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m bestTest = 0.5369106642\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m bestTest = 0.1553724337\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m bestIteration = 829\n",
      "\u001b[36m(_ray_fit pid=1088)\u001b[0m Shrink model to first 830 iterations.\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m 160:\tlearn: 0.1484977\ttest: 0.1518719\tbest: 0.1518719 (160)\ttotal: 3.89s\tremaining: 2m 43s\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m bestTest = 0.537135674\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m 100:\tlearn: 0.1523650\ttest: 0.1566756\tbest: 0.1566756 (100)\ttotal: 2.36s\tremaining: 2m 44s\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m 320:\tlearn: 0.1441081\ttest: 0.1513296\tbest: 0.1513296 (320)\ttotal: 7.45s\tremaining: 2m 37s\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m bestTest = 0.1496388224\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m bestIteration = 551\n",
      "\u001b[36m(_ray_fit pid=1141)\u001b[0m Shrink model to first 552 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m 540:\tlearn: 0.1401604\ttest: 0.1504798\tbest: 0.1504798 (540)\ttotal: 12.7s\tremaining: 2m 34s\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m bestTest = 0.5363452038\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m 760:\tlearn: 0.1368372\ttest: 0.1501964\tbest: 0.1501874 (756)\ttotal: 17.8s\tremaining: 2m 28s\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m bestTest = 0.1501730177\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m bestIteration = 784\n",
      "\u001b[36m(_ray_fit pid=1186)\u001b[0m Shrink model to first 785 iterations.\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m 420:\tlearn: 0.1424325\ttest: 0.1473181\tbest: 0.1473181 (420)\ttotal: 9.74s\tremaining: 2m 27s\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m bestTest = 0.5368067799\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m 640:\tlearn: 0.1387766\ttest: 0.1469729\tbest: 0.1469644 (638)\ttotal: 14.8s\tremaining: 2m 21s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m bestTest = 0.1468876841\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m bestIteration = 671\n",
      "\u001b[36m(_ray_fit pid=1231)\u001b[0m Shrink model to first 672 iterations.\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m 340:\tlearn: 0.1445897\ttest: 0.1454778\tbest: 0.1454778 (340)\ttotal: 7.86s\tremaining: 2m 40s\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m 580:\tlearn: 0.1405214\ttest: 0.1447648\tbest: 0.1447648 (580)\ttotal: 12.9s\tremaining: 2m 29s\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m bestTest = 0.1447502785\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m bestIteration = 639\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m Shrink model to first 640 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9757\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t93.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t10799.2\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 5191.58s of the 7891.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.17s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9724\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t37788.8\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 5179.12s of the 7878.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.4s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9725\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t37192.1\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 5166.38s of the 7866.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting XGBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.15%)\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:23] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m   warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m [0]\tvalidation_0-logloss:0.42494\n",
      "\u001b[36m(_ray_fit pid=1276)\u001b[0m 680:\tlearn: 0.1390885\ttest: 0.1448209\tbest: 0.1447503 (639)\ttotal: 15s\tremaining: 2m 25s\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=1363)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:27] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1421)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1421)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1421)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1421)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:29] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m Potential solutions:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1423)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1481)\u001b[0m [0]\tvalidation_0-logloss:0.42536\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:36] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m \u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m Potential solutions:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1541)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m [200]\tvalidation_0-logloss:0.14726\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.975\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t14.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t42047.8\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5149.69s of the 7849.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.09%)\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:36] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1609)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:14:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=1610)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1610)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1610)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1610)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1678)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1680)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1748)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1776)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1818)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1853)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.974\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t190.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t28046.1\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4957.01s of the 7656.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.14%)\n",
      "\u001b[36m(_ray_fit pid=1895)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1895)\u001b[0m [50]\tvalid_set's binary_logloss: 0.200093\n",
      "\u001b[36m(_ray_fit pid=1543)\u001b[0m [236]\tvalidation_0-logloss:0.14748\n",
      "\u001b[36m(_ray_fit pid=1895)\u001b[0m [250]\tvalid_set's binary_logloss: 0.158366\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m [50]\tvalid_set's binary_logloss: 0.201435\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1967)\u001b[0m [250]\tvalid_set's binary_logloss: 0.161886\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2035)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2035)\u001b[0m [50]\tvalid_set's binary_logloss: 0.197081\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2035)\u001b[0m [250]\tvalid_set's binary_logloss: 0.153351\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2106)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2106)\u001b[0m [50]\tvalid_set's binary_logloss: 0.196553\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2106)\u001b[0m [250]\tvalid_set's binary_logloss: 0.152138\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9739\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t46.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.63s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t4309.1\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 539.52s of the 7607.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\u001b[36m(_ray_fit pid=2108)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Ensemble size: 14\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m [0.21428571 0.         0.         0.         0.5        0.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m  0.         0.07142857 0.14285714 0.07142857]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.46s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.214, 'NeuralNetTorch_BAG_L1': 0.143, 'XGBoost_BAG_L1': 0.071, 'LightGBMLarge_BAG_L1': 0.071}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.976\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1762.9\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Excluded models: ['FASTAI'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 10 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 7602.91s of the 7602.89s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.22%)\n",
      "\u001b[36m(_ray_fit pid=2191)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2191)\u001b[0m [50]\tvalid_set's binary_logloss: 0.159077\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2259)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2259)\u001b[0m [50]\tvalid_set's binary_logloss: 0.161404\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2329)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2329)\u001b[0m [50]\tvalid_set's binary_logloss: 0.157446\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2400)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2400)\u001b[0m [50]\tvalid_set's binary_logloss: 0.162433\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9754\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t24.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1126.3\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 7576.78s of the 7576.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.22%)\n",
      "\u001b[36m(_ray_fit pid=2484)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2484)\u001b[0m [50]\tvalid_set's binary_logloss: 0.15702\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2552)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2552)\u001b[0m [50]\tvalid_set's binary_logloss: 0.160165\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2623)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2623)\u001b[0m [50]\tvalid_set's binary_logloss: 0.157088\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2693)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2693)\u001b[0m [50]\tvalid_set's binary_logloss: 0.160631\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9751\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t23.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.81s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1153.3\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 7551.09s of the 7551.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting RandomForestGini_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.9s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_ray_fit pid=2719)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9752\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t41.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1193.1\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 7506.39s of the 7506.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting RandomForestEntr_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t19.81s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9754\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t43.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1193.6\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 7459.57s of the 7459.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting CatBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.24%)\n",
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m 0:\tlearn: 0.6039098\ttest: 0.6039314\tbest: 0.6039314 (0)\ttotal: 33.2ms\tremaining: 133ms\n",
      "\u001b[36m(_ray_fit pid=2719)\u001b[0m [150]\tvalid_set's binary_logloss: 0.150746\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m 4:\tlearn: 0.3877157\ttest: 0.3871703\tbest: 0.3871703 (4)\ttotal: 136ms\tremaining: 0us\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m bestTest = 0.3871703024\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m 160:\tlearn: 0.1458943\ttest: 0.1477993\tbest: 0.1477815 (145)\ttotal: 3.58s\tremaining: 2m 3s\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m bestTest = 0.3894728824\n",
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m bestTest = 0.1477644814\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m bestIteration = 182\n",
      "\u001b[36m(_ray_fit pid=2805)\u001b[0m Shrink model to first 183 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m 380:\tlearn: 0.1407062\ttest: 0.1519756\tbest: 0.1519032 (343)\ttotal: 8.93s\tremaining: 1m 25s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m bestTest = 0.3867642579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m bestIteration = 4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2804)\u001b[0m Shrink model to first 344 iterations.\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m 160:\tlearn: 0.1455348\ttest: 0.1513643\tbest: 0.1513643 (160)\ttotal: 3.61s\tremaining: 2m 36s\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2931)\u001b[0m bestTest = 0.3880449772\n",
      "\u001b[36m(_ray_fit pid=2931)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m bestTest = 0.1512249166\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m bestIteration = 237\n",
      "\u001b[36m(_ray_fit pid=2887)\u001b[0m Shrink model to first 238 iterations.\n",
      "\u001b[36m(_ray_fit pid=2931)\u001b[0m 200:\tlearn: 0.1445309\ttest: 0.1512952\tbest: 0.1512952 (200)\ttotal: 5s\tremaining: 3m\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m bestTest = 0.3893357538\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m bestIteration = 4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2931)\u001b[0m Shrink model to first 208 iterations.\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m 80:\tlearn: 0.1483727\ttest: 0.1456877\tbest: 0.1456877 (80)\ttotal: 1.75s\tremaining: 1m 57s\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3018)\u001b[0m bestTest = 0.3908205874\n",
      "\u001b[36m(_ray_fit pid=3018)\u001b[0m bestIteration = 4\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m bestTest = 0.1446949943\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m bestIteration = 217\n",
      "\u001b[36m(_ray_fit pid=2978)\u001b[0m Shrink model to first 218 iterations.\n",
      "\u001b[36m(_ray_fit pid=3018)\u001b[0m 160:\tlearn: 0.1461284\ttest: 0.1477033\tbest: 0.1477033 (160)\ttotal: 4.63s\tremaining: 3m 33s\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m bestTest = 0.3892735357\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m bestIteration = 4\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3018)\u001b[0m Shrink model to first 201 iterations.\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m 40:\tlearn: 0.1534816\ttest: 0.1557319\tbest: 0.1557319 (40)\ttotal: 844ms\tremaining: 2m\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m Shrink model to first 173 iterations.\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m bestTest = 0.1501945691\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3068)\u001b[0m bestIteration = 172\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m 140:\tlearn: 0.1462534\ttest: 0.1491639\tbest: 0.1491380 (133)\ttotal: 3.27s\tremaining: 2m 45s\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9757\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t47.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.81s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1153.4\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 7410.55s of the 7410.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting ExtraTreesGini_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t19.83s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9755\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t9.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1189.6\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 7397.87s of the 7397.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting ExtraTreesEntr_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t22.04s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9754\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t9.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1190.4\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 7384.92s of the 7384.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting XGBoost_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.30%)\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:25] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m   warnings.warn(smsg, UserWarning)\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m   warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m [0]\tvalidation_0-logloss:0.41906\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m Shrink model to first 201 iterations.\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m bestTest = 0.1490358655\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m bestIteration = 200\n",
      "\u001b[36m(_ray_fit pid=3108)\u001b[0m 240:\tlearn: 0.1442774\ttest: 0.1490942\tbest: 0.1490359 (200)\ttotal: 5.32s\tremaining: 2m 35s\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m Potential solutions:\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m - Set the device for booster before call to inplace_predict.\n",
      "\u001b[36m(_ray_fit pid=3206)\u001b[0m This warning will only be shown once.\n",
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:33] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m \u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3264)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3264)\u001b[0m Potential solutions:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3264)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3264)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3264)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3327)\u001b[0m [0]\tvalidation_0-logloss:0.41922\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9756\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t14.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1189.2\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 7368.64s of the 7368.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.19%)\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:37] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m \u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:22:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m Potential solutions:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m - Set the device for booster before call to inplace_predict.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m This warning will only be shown once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3459)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3460)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3528)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3560)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3626)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3598)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3668)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9749\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t180.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.95s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1141.9\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 7186.55s of the 7186.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 2, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.28%)\n",
      "\u001b[36m(_ray_fit pid=3752)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=3696)\u001b[0m   self.model = torch.load(net_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3752)\u001b[0m [50]\tvalid_set's binary_logloss: 0.188037\n",
      "\u001b[36m(_ray_fit pid=3388)\u001b[0m [104]\tvalidation_0-logloss:0.14920\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3822)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3822)\u001b[0m [50]\tvalid_set's binary_logloss: 0.185385\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3893)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3893)\u001b[0m [50]\tvalid_set's binary_logloss: 0.183077\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3963)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=3963)\u001b[0m [50]\tvalid_set's binary_logloss: 0.186548\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.975\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t36.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.41s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1104.3\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_ray_fit pid=3965)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Model configs that will be trained (in order):\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 760.29s of the 7147.4s of remaining time.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 4\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Ensemble size: 23\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Ensemble weights: \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m [0.13043478 0.         0.         0.         0.34782609 0.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m  0.         0.04347826 0.08695652 0.04347826 0.         0.04347826\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m  0.08695652 0.04347826 0.         0.         0.         0.04347826\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m  0.13043478]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.01s\t= Estimated out-of-fold prediction time...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.348, 'LightGBMXT_BAG_L1': 0.13, 'LightGBMLarge_BAG_L2': 0.13, 'NeuralNetTorch_BAG_L1': 0.087, 'RandomForestEntr_BAG_L2': 0.087, 'XGBoost_BAG_L1': 0.043, 'LightGBMXT_BAG_L2': 0.043, 'RandomForestGini_BAG_L2': 0.043, 'CatBoost_BAG_L2': 0.043, 'NeuralNetTorch_BAG_L2': 0.043}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.9761\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t880.4\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m AutoGluon training complete, total runtime = 957.29s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 880.4 rows/s (15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 199 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.14s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 172 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t14.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.27s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t38194.0\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t15.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t40339.2\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting CatBoost_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tCatboost model hyperparameters: {'iterations': 676, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m 0:\tlearn: 0.6101317\ttotal: 175ms\tremaining: 1m 57s\n",
      "\u001b[36m(_ray_fit pid=3965)\u001b[0m [200]\tvalid_set's binary_logloss: 0.151456\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 20:\tlearn: 0.1989589\ttotal: 2.37s\tremaining: 1m 14s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 40:\tlearn: 0.1689064\ttotal: 4.35s\tremaining: 1m 7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 60:\tlearn: 0.1592681\ttotal: 6.37s\tremaining: 1m 4s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 80:\tlearn: 0.1550019\ttotal: 8.41s\tremaining: 1m 1s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 100:\tlearn: 0.1525682\ttotal: 10.4s\tremaining: 59.2s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 120:\tlearn: 0.1508313\ttotal: 12.3s\tremaining: 56.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 140:\tlearn: 0.1496880\ttotal: 14.3s\tremaining: 54.2s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 160:\tlearn: 0.1488153\ttotal: 16.3s\tremaining: 52.2s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 180:\tlearn: 0.1480645\ttotal: 18.2s\tremaining: 49.8s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 200:\tlearn: 0.1473809\ttotal: 20.3s\tremaining: 48s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 220:\tlearn: 0.1467867\ttotal: 22.2s\tremaining: 45.8s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 240:\tlearn: 0.1462372\ttotal: 24.2s\tremaining: 43.7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 260:\tlearn: 0.1457078\ttotal: 26.3s\tremaining: 41.9s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 280:\tlearn: 0.1452183\ttotal: 28.4s\tremaining: 39.9s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 300:\tlearn: 0.1447789\ttotal: 30.4s\tremaining: 37.9s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 320:\tlearn: 0.1444370\ttotal: 32.4s\tremaining: 35.8s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 340:\tlearn: 0.1440826\ttotal: 34.3s\tremaining: 33.7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 360:\tlearn: 0.1437148\ttotal: 36.2s\tremaining: 31.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 380:\tlearn: 0.1433308\ttotal: 38.2s\tremaining: 29.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 400:\tlearn: 0.1430382\ttotal: 40.2s\tremaining: 27.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 420:\tlearn: 0.1426852\ttotal: 42.2s\tremaining: 25.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 440:\tlearn: 0.1424011\ttotal: 44.3s\tremaining: 23.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 460:\tlearn: 0.1421029\ttotal: 46.2s\tremaining: 21.5s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 480:\tlearn: 0.1418534\ttotal: 48.2s\tremaining: 19.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 500:\tlearn: 0.1415057\ttotal: 50.2s\tremaining: 17.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 520:\tlearn: 0.1412212\ttotal: 52.2s\tremaining: 15.5s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 540:\tlearn: 0.1408873\ttotal: 54.1s\tremaining: 13.5s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 560:\tlearn: 0.1405879\ttotal: 56.1s\tremaining: 11.5s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 580:\tlearn: 0.1402836\ttotal: 58.2s\tremaining: 9.52s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 600:\tlearn: 0.1399903\ttotal: 1m\tremaining: 7.53s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 620:\tlearn: 0.1397420\ttotal: 1m 2s\tremaining: 5.53s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 640:\tlearn: 0.1395074\ttotal: 1m 4s\tremaining: 3.52s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 660:\tlearn: 0.1392132\ttotal: 1m 6s\tremaining: 1.52s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 675:\tlearn: 0.1389913\ttotal: 1m 8s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t69.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t37788.8\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t37192.1\t = Inference  throughput (rows/s | 125066 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting XGBoost_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting NeuralNetTorch_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Age\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Academic Pressure\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Work Pressure\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"CGPA\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Study Satisfaction\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Job Satisfaction\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Work/Study Hours\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Financial Stress\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"skewed\": [],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"onehot\": [],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"embed\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Name\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"City\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Profession\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Sleep Duration\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Dietary Habits\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Degree\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Gender\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Working Professional or Student\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Have you ever had suicidal thoughts ?\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Family History of Mental Illness\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training data for TabularNeuralNetTorchModel has: 125066 examples, 18 features (12 vector, 6 embedding)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training on CPU\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (embed_blocks): ModuleList(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (0): Embedding(102, 21)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (1-2): 2 x Embedding(47, 13)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (3): Embedding(19, 8)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (4): Embedding(8, 5)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (5): Embedding(46, 13)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (0): Linear(in_features=85, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (11): Linear(in_features=128, out_features=2, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (softmax): Softmax(dim=1)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training tabular neural network for up to 6 epochs...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Best model found on Epoch 0 (Update 0).\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t14.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMLarge_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 212 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.214, 'NeuralNetTorch_BAG_L1': 0.143, 'XGBoost_BAG_L1': 0.071, 'LightGBMLarge_BAG_L1': 0.071}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t4.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMXT_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 118 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBM_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 112 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t41.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1193.1\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t43.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1193.6\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting CatBoost_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tCatboost model hyperparameters: {'iterations': 221, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m 0:\tlearn: 0.6019859\ttotal: 112ms\tremaining: 24.7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 20:\tlearn: 0.1736617\ttotal: 2.7s\tremaining: 25.7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 40:\tlearn: 0.1527214\ttotal: 4.68s\tremaining: 20.6s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 60:\tlearn: 0.1495503\ttotal: 6.59s\tremaining: 17.3s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 80:\tlearn: 0.1484237\ttotal: 8.83s\tremaining: 15.3s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 100:\tlearn: 0.1479036\ttotal: 10.9s\tremaining: 13s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 120:\tlearn: 0.1474861\ttotal: 13s\tremaining: 10.7s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 140:\tlearn: 0.1470822\ttotal: 15s\tremaining: 8.53s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 160:\tlearn: 0.1467193\ttotal: 17.1s\tremaining: 6.36s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 180:\tlearn: 0.1463675\ttotal: 19.1s\tremaining: 4.22s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 200:\tlearn: 0.1460679\ttotal: 21.1s\tremaining: 2.1s\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m 220:\tlearn: 0.1457183\ttotal: 23.2s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t23.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t9.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1189.6\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t9.44s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t3.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1190.4\t = Inference  throughput (rows/s | 15634 batch size)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting XGBoost_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t1.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting NeuralNetTorch_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   return dtype.type(n)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   adjusted3 = adjusted2 * adjusted\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Tabular Neural Network treats features as the following types:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"continuous\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Age\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Academic Pressure\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Work Pressure\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"CGPA\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Study Satisfaction\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Job Satisfaction\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Work/Study Hours\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Financial Stress\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"skewed\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"LightGBMXT_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"LightGBM_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"RandomForestGini_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"RandomForestEntr_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"CatBoost_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"ExtraTreesGini_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"ExtraTreesEntr_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"XGBoost_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"NeuralNetTorch_BAG_L1\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"LightGBMLarge_BAG_L1\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"onehot\": [],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"embed\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Name\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"City\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Profession\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Sleep Duration\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Dietary Habits\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Degree\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"language\": [],\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     \"bool\": [\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Gender\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Working Professional or Student\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Have you ever had suicidal thoughts ?\",\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m         \"Family History of Mental Illness\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     ]\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training data for TabularNeuralNetTorchModel has: 125066 examples, 28 features (22 vector, 6 embedding)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training on CPU\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Neural network architecture:\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m EmbedNet(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (embed_blocks): ModuleList(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (0): Embedding(102, 21)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (1-2): 2 x Embedding(47, 13)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (3): Embedding(19, 8)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (4): Embedding(8, 5)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (5): Embedding(46, 13)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (main_block): Sequential(\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (0): Linear(in_features=95, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (1): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (2): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (4): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (5): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (7): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (8): Dropout(p=0.1, inplace=False)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (10): ReLU()\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m     (11): Linear(in_features=128, out_features=2, bias=True)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   (softmax): Softmax(dim=1)\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m )\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Training tabular neural network for up to 4 epochs...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Best model found on Epoch 0 (Update 0).\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t10.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting LightGBMLarge_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/utils/model_template.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tFitting 159 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t2.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.348, 'LightGBMXT_BAG_L1': 0.13, 'LightGBMLarge_BAG_L2': 0.13, 'NeuralNetTorch_BAG_L1': 0.087, 'RandomForestEntr_BAG_L2': 0.087, 'XGBoost_BAG_L1': 0.043, 'LightGBMXT_BAG_L2': 0.043, 'RandomForestGini_BAG_L2': 0.043, 'CatBoost_BAG_L2': 0.043, 'NeuralNetTorch_BAG_L2': 0.043}\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m \t8.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Refit complete, total runtime = 140.12s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.1.1\"\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Saving AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/metadata.json\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesGini_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/ExtraTreesEntr_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/XGBoost_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/NeuralNetTorch_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/LightGBMLarge_BAG_L2_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Loading: AutogluonModels/ag-20241118_171021/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
      "\u001b[36m(_dystack pid=188)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2_FULL       0.976255   0.976026     roc_auc        0.741334            NaN   96.009277                 0.003544                     NaN           4.688692            2       True         11\n",
      "1       WeightedEnsemble_L3_FULL       0.976251   0.976099     roc_auc        3.877348            NaN  273.079462                 0.005574                     NaN           8.890481            3       True         22\n",
      "2           CatBoost_BAG_L2_FULL       0.976157   0.975700     roc_auc        2.998607            NaN  164.354161                 0.053530                     NaN          23.850399            2       True         16\n",
      "3            XGBoost_BAG_L2_FULL       0.976149   0.975642     roc_auc        3.006455            NaN  142.038630                 0.061379                     NaN           1.534868            2       True         19\n",
      "4           CatBoost_BAG_L1_FULL       0.976012   0.975700     roc_auc        0.080282            NaN   69.523592                 0.080282                     NaN          69.523592            1       True          5\n",
      "5     ExtraTreesEntr_BAG_L2_FULL       0.975965   0.975411     roc_auc        3.254085            NaN  149.948603                 0.309009                3.099422           9.444841            2       True         18\n",
      "6     ExtraTreesGini_BAG_L2_FULL       0.975899   0.975462     roc_auc        3.268906            NaN  149.625442                 0.323830                3.167786           9.121680            2       True         17\n",
      "7   RandomForestGini_BAG_L2_FULL       0.975673   0.975163     roc_auc        3.258157            NaN  181.995074                 0.313080                2.858527          41.491312            2       True         14\n",
      "8         LightGBMXT_BAG_L2_FULL       0.975667   0.975392     roc_auc        3.020260            NaN  142.143471                 0.075183                     NaN           1.639709            2       True         12\n",
      "9     NeuralNetTorch_BAG_L2_FULL       0.975621   0.974901     roc_auc        3.064364            NaN  150.823910                 0.119287                     NaN          10.320148            2       True         20\n",
      "10  RandomForestEntr_BAG_L2_FULL       0.975600   0.975372     roc_auc        3.212907            NaN  184.205985                 0.267830                2.816753          43.702223            2       True         15\n",
      "11           XGBoost_BAG_L1_FULL       0.975521   0.975017     roc_auc        0.103131            NaN    2.169981                 0.103131                     NaN           2.169981            1       True          8\n",
      "12     LightGBMLarge_BAG_L2_FULL       0.975283   0.974953     roc_auc        3.042863            NaN  143.185190                 0.097786                     NaN           2.681428            2       True         21\n",
      "13          LightGBM_BAG_L2_FULL       0.975264   0.975115     roc_auc        2.992747            NaN  142.065826                 0.047670                     NaN           1.562064            2       True         13\n",
      "14        LightGBMXT_BAG_L1_FULL       0.975209   0.975015     roc_auc        0.187008            NaN    2.136646                 0.187008                     NaN           2.136646            1       True          1\n",
      "15    NeuralNetTorch_BAG_L1_FULL       0.974485   0.974037     roc_auc        0.122308            NaN   14.166719                 0.122308                     NaN          14.166719            1       True          9\n",
      "16          LightGBM_BAG_L1_FULL       0.974472   0.974017     roc_auc        0.157078            NaN    1.926502                 0.157078                     NaN           1.926502            1       True          2\n",
      "17     LightGBMLarge_BAG_L1_FULL       0.974254   0.973852     roc_auc        0.245060            NaN    3.323646                 0.245060                     NaN           3.323646            1       True         10\n",
      "18  RandomForestEntr_BAG_L1_FULL       0.973680   0.972814     roc_auc        0.451835       3.100356   15.046560                 0.451835                3.100356          15.046560            1       True          4\n",
      "19    ExtraTreesGini_BAG_L1_FULL       0.973192   0.972365     roc_auc        0.565694       3.309601    8.553970                 0.565694                3.309601           8.553970            1       True          6\n",
      "20    ExtraTreesEntr_BAG_L1_FULL       0.973185   0.972516     roc_auc        0.529164       3.362707    8.808350                 0.529164                3.362707           8.808350            1       True          7\n",
      "21  RandomForestGini_BAG_L1_FULL       0.973012   0.972517     roc_auc        0.503516       3.274494   14.847796                 0.503516                3.274494          14.847796            1       True          3\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1109s\t = DyStack   runtime |\t31291s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Saving AutogluonModels/ag-20241118_171021/learner.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 31291s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241118_171021\"\n",
      "Train Data Rows:    140700\n",
      "Train Data Columns: 18\n",
      "Label Column:       Depression\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29062.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 87.60 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float16', 'float') :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('object', 'object') : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t\t('object', [])    : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\t0.0s = Fit runtime\n",
      "\t\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t6 features in original data used to generate 6 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "/opt/conda/lib/python3.10/site-packages/autogluon/features/generators/drop_duplicates.py:100: RuntimeWarning: overflow encountered in multiply\n",
      "  feature_sum_map[round(X[feature].sum(), 2)].append(feature)\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float16', 'float') :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('object', 'object') : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t('float16', 'float')     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('int8', 'int')          : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t1.0s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.63 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving AutogluonModels/ag-20241118_171021/learner.pkl\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Saving AutogluonModels/ag-20241118_171021/utils/data/X.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/utils/data/y.pkl\n",
      "Excluded models: ['FASTAI'] (Specified by `excluded_model_types`)\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}, 'ag_args_fit': {'num_gpus': 1}}\n",
      "Fitting 10 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 31289.76s of the 31289.75s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.09%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.9749\t = Validation score   (roc_auc)\n",
      "\t33.43s\t = Training   runtime\n",
      "\t3.44s\t = Validation runtime\n",
      "\t5117.7\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 31252.64s of the 31252.63s of remaining time.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.09%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.9743\t = Validation score   (roc_auc)\n",
      "\t30.86s\t = Training   runtime\n",
      "\t2.77s\t = Validation runtime\n",
      "\t6347.7\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 31219.53s of the 31219.52s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\t25.62s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.9726\t = Validation score   (roc_auc)\n",
      "\t17.58s\t = Training   runtime\n",
      "\t4.16s\t = Validation runtime\n",
      "\t33822.0\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 31197.12s of the 31197.11s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\t25.04s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.9732\t = Validation score   (roc_auc)\n",
      "\t16.84s\t = Training   runtime\n",
      "\t4.07s\t = Validation runtime\n",
      "\t34576.9\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 31175.63s of the 31175.62s of remaining time.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.10%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/model.pkl\n",
      "\t0.9757\t = Validation score   (roc_auc)\n",
      "\t91.67s\t = Training   runtime\n",
      "\t1.6s\t = Validation runtime\n",
      "\t10994.6\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 31081.85s of the 31081.84s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\t25.16s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.9726\t = Validation score   (roc_auc)\n",
      "\t10.73s\t = Training   runtime\n",
      "\t4.45s\t = Validation runtime\n",
      "\t31619.0\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 31066.02s of the 31066.01s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\t25.21s\t= Estimated out-of-fold prediction time...\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.9727\t = Validation score   (roc_auc)\n",
      "\t10.27s\t = Training   runtime\n",
      "\t4.4s\t = Validation runtime\n",
      "\t31993.3\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 31050.76s of the 31050.75s of remaining time.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.13%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.9752\t = Validation score   (roc_auc)\n",
      "\t16.15s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "\t39981.9\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 31032.74s of the 31032.73s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.07%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.9739\t = Validation score   (roc_auc)\n",
      "\t214.57s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "\t28872.7\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 30816.22s of the 30816.21s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 2, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.13%)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.9739\t = Validation score   (roc_auc)\n",
      "\t51.01s\t = Training   runtime\n",
      "\t4.26s\t = Validation runtime\n",
      "\t4130.6\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 3128.98s of the 30762.45s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 4\n",
      "Saving AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 18\n",
      "Ensemble weights: \n",
      "[0.16666667 0.05555556 0.         0.         0.5        0.\n",
      " 0.         0.11111111 0.11111111 0.05555556]\n",
      "\t0.89s\t= Estimated out-of-fold prediction time...\n",
      "Saving AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.111, 'NeuralNetTorch_BAG_L1': 0.111, 'LightGBM_BAG_L1': 0.056, 'LightGBMLarge_BAG_L1': 0.056}\n",
      "\t0.976\t = Validation score   (roc_auc)\n",
      "\t5.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t1340.8\t = Inference  throughput (rows/s | 17588 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 533.93s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1340.8 rows/s (17588 batch size)\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Loading: AutogluonModels/ag-20241118_171021/utils/data/X.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/utils/data/y.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tFitting 212 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "\t2.52s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tFitting 183 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "\t2.64s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t17.58s\t = Training   runtime\n",
      "\t4.16s\t = Validation runtime\n",
      "\t33822.0\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t16.84s\t = Training   runtime\n",
      "\t4.07s\t = Validation runtime\n",
      "\t34576.9\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\tFitting CatBoost_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tCatboost model hyperparameters: {'iterations': 624, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6097180\ttotal: 194ms\tremaining: 2m\n",
      "20:\tlearn: 0.1991451\ttotal: 2.51s\tremaining: 1m 12s\n",
      "40:\tlearn: 0.1687829\ttotal: 4.78s\tremaining: 1m 7s\n",
      "60:\tlearn: 0.1591815\ttotal: 6.98s\tremaining: 1m 4s\n",
      "80:\tlearn: 0.1549842\ttotal: 9.23s\tremaining: 1m 1s\n",
      "100:\tlearn: 0.1524175\ttotal: 11.5s\tremaining: 59.4s\n",
      "120:\tlearn: 0.1508880\ttotal: 13.7s\tremaining: 56.9s\n",
      "140:\tlearn: 0.1497247\ttotal: 15.9s\tremaining: 54.4s\n",
      "160:\tlearn: 0.1488923\ttotal: 18.1s\tremaining: 52s\n",
      "180:\tlearn: 0.1481386\ttotal: 20.3s\tremaining: 49.6s\n",
      "200:\tlearn: 0.1475121\ttotal: 22.3s\tremaining: 47s\n",
      "220:\tlearn: 0.1470143\ttotal: 24.9s\tremaining: 45.4s\n",
      "240:\tlearn: 0.1465286\ttotal: 27.1s\tremaining: 43s\n",
      "260:\tlearn: 0.1460090\ttotal: 29.2s\tremaining: 40.7s\n",
      "280:\tlearn: 0.1455664\ttotal: 31.5s\tremaining: 38.4s\n",
      "300:\tlearn: 0.1451289\ttotal: 33.7s\tremaining: 36.2s\n",
      "320:\tlearn: 0.1447962\ttotal: 36.1s\tremaining: 34.1s\n",
      "340:\tlearn: 0.1444105\ttotal: 38.3s\tremaining: 31.8s\n",
      "360:\tlearn: 0.1441360\ttotal: 40.6s\tremaining: 29.6s\n",
      "380:\tlearn: 0.1438719\ttotal: 42.8s\tremaining: 27.3s\n",
      "400:\tlearn: 0.1435917\ttotal: 44.9s\tremaining: 24.9s\n",
      "420:\tlearn: 0.1432848\ttotal: 47.1s\tremaining: 22.7s\n",
      "440:\tlearn: 0.1430322\ttotal: 49.1s\tremaining: 20.4s\n",
      "460:\tlearn: 0.1427382\ttotal: 51.2s\tremaining: 18.1s\n",
      "480:\tlearn: 0.1424760\ttotal: 53.4s\tremaining: 15.9s\n",
      "500:\tlearn: 0.1421885\ttotal: 56.1s\tremaining: 13.8s\n",
      "520:\tlearn: 0.1419250\ttotal: 58.3s\tremaining: 11.5s\n",
      "540:\tlearn: 0.1416688\ttotal: 1m\tremaining: 9.27s\n",
      "560:\tlearn: 0.1414260\ttotal: 1m 2s\tremaining: 7.04s\n",
      "580:\tlearn: 0.1411980\ttotal: 1m 4s\tremaining: 4.8s\n",
      "600:\tlearn: 0.1409437\ttotal: 1m 7s\tremaining: 2.57s\n",
      "620:\tlearn: 0.1406866\ttotal: 1m 9s\tremaining: 335ms\n",
      "623:\tlearn: 0.1406487\ttotal: 1m 9s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "\t70.55s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.73s\t = Training   runtime\n",
      "\t4.45s\t = Validation runtime\n",
      "\t31619.0\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.27s\t = Training   runtime\n",
      "\t4.4s\t = Validation runtime\n",
      "\t31993.3\t = Inference  throughput (rows/s | 140700 batch size)\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\tFitting XGBoost_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/utils/model_template.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "\t2.43s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\tFitting NeuralNetTorch_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/utils/model_template.pkl\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "  return dtype.type(n)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1260: RuntimeWarning: overflow encountered in multiply\n",
      "  adjusted3 = adjusted2 * adjusted\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"Age\",\n",
      "        \"Academic Pressure\",\n",
      "        \"Work Pressure\",\n",
      "        \"CGPA\",\n",
      "        \"Study Satisfaction\",\n",
      "        \"Job Satisfaction\",\n",
      "        \"Work/Study Hours\",\n",
      "        \"Financial Stress\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [\n",
      "        \"Name\",\n",
      "        \"City\",\n",
      "        \"Profession\",\n",
      "        \"Sleep Duration\",\n",
      "        \"Dietary Habits\",\n",
      "        \"Degree\"\n",
      "    ],\n",
      "    \"language\": [],\n",
      "    \"bool\": [\n",
      "        \"Gender\",\n",
      "        \"Working Professional or Student\",\n",
      "        \"Have you ever had suicidal thoughts ?\",\n",
      "        \"Family History of Mental Illness\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 140700 examples, 18 features (12 vector, 6 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (embed_blocks): ModuleList(\n",
      "    (0): Embedding(102, 21)\n",
      "    (1): Embedding(48, 13)\n",
      "    (2): Embedding(47, 13)\n",
      "    (3): Embedding(20, 8)\n",
      "    (4): Embedding(9, 5)\n",
      "    (5): Embedding(48, 13)\n",
      "  )\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=85, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 7 epochs...\n",
      "Best model found on Epoch 0 (Update 0).\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "\t18.06s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\tFitting LightGBMLarge_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 2\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/utils/model_template.pkl\n",
      "\tFitting 218 rounds... Hyperparameters: {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "\t3.74s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/model.pkl\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.111, 'NeuralNetTorch_BAG_L1': 0.111, 'LightGBM_BAG_L1': 0.056, 'LightGBMLarge_BAG_L1': 0.056}\n",
      "\t5.47s\t = Training   runtime\n",
      "Saving AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2_FULL/model.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 102.66s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "Saving AutogluonModels/ag-20241118_171021/models/trainer.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/learner.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/predictor.pkl\n",
      "Saving AutogluonModels/ag-20241118_171021/version.txt with contents \"1.1.1\"\n",
      "Saving AutogluonModels/ag-20241118_171021/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241118_171021\")\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesGini_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/ExtraTreesEntr_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2_FULL/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                           model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0            WeightedEnsemble_L2   0.976037     roc_auc      13.138355  443.156132                0.024113           5.465805            2      False         11\n",
      "1                CatBoost_BAG_L1   0.975710     roc_auc       1.599690   91.672231                1.599690          91.672231            1      False          5\n",
      "2                 XGBoost_BAG_L1   0.975152     roc_auc       0.439899   16.146794                0.439899          16.146794            1      False          8\n",
      "3              LightGBMXT_BAG_L1   0.974945     roc_auc       3.436720   33.432083                3.436720          33.432083            1      False          1\n",
      "4                LightGBM_BAG_L1   0.974291     roc_auc       2.770787   30.861857                2.770787          30.861857            1      False          2\n",
      "5           LightGBMLarge_BAG_L1   0.973938     roc_auc       4.257989   51.010804                4.257989          51.010804            1      False         10\n",
      "6          NeuralNetTorch_BAG_L1   0.973863     roc_auc       0.609156  214.566558                0.609156         214.566558            1      False          9\n",
      "7        RandomForestEntr_BAG_L1   0.973155     roc_auc       4.069196   16.838439                4.069196          16.838439            1       True          4\n",
      "8          ExtraTreesEntr_BAG_L1   0.972718     roc_auc       4.397800   10.268695                4.397800          10.268695            1       True          7\n",
      "9          ExtraTreesGini_BAG_L1   0.972588     roc_auc       4.449863   10.725438                4.449863          10.725438            1       True          6\n",
      "10       RandomForestGini_BAG_L1   0.972581     roc_auc       4.160010   17.583482                4.160010          17.583482            1       True          3\n",
      "11  RandomForestEntr_BAG_L1_FULL        NaN     roc_auc       4.069196   16.838439                4.069196          16.838439            1       True         15\n",
      "12  RandomForestGini_BAG_L1_FULL        NaN     roc_auc       4.160010   17.583482                4.160010          17.583482            1       True         14\n",
      "13    ExtraTreesEntr_BAG_L1_FULL        NaN     roc_auc       4.397800   10.268695                4.397800          10.268695            1       True         18\n",
      "14    ExtraTreesGini_BAG_L1_FULL        NaN     roc_auc       4.449863   10.725438                4.449863          10.725438            1       True         17\n",
      "15           XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN    2.425326                     NaN           2.425326            1       True         19\n",
      "16      WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN  105.403707                     NaN           5.465805            2       True         22\n",
      "17    NeuralNetTorch_BAG_L1_FULL        NaN     roc_auc            NaN   18.058267                     NaN          18.058267            1       True         20\n",
      "18          LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN    2.639776                     NaN           2.639776            1       True         13\n",
      "19        LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN    2.516361                     NaN           2.516361            1       True         12\n",
      "20     LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN    3.744808                     NaN           3.744808            1       True         21\n",
      "21          CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   70.553364                     NaN          70.553364            1       True         16\n",
      "Number of models trained: 22\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_TabularNeuralNetTorch'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20241118_171021SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,eval_metric ='roc_auc',\n",
    "                            problem_type=\"binary\").fit(train,presets='good_quality',\n",
    "                                                                    time_limit=3600*9,verbosity=3,\n",
    "                                                       ag_args_fit={'num_gpus': 1},\n",
    "                                                       excluded_model_types=['FASTAI']\n",
    "                                                      )\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "696ffc4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:39:31.717901Z",
     "iopub.status.busy": "2024-11-18T17:39:31.716645Z",
     "iopub.status.idle": "2024-11-18T17:39:31.736655Z",
     "shell.execute_reply": "2024-11-18T17:39:31.735800Z"
    },
    "papermill": {
     "duration": 0.108472,
     "end_time": "2024-11-18T17:39:31.738378",
     "exception": false,
     "start_time": "2024-11-18T17:39:31.629906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.976037</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>13.138355</td>\n",
       "      <td>443.156132</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>5.465805</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.975710</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.599690</td>\n",
       "      <td>91.672231</td>\n",
       "      <td>1.599690</td>\n",
       "      <td>91.672231</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.975152</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.439899</td>\n",
       "      <td>16.146794</td>\n",
       "      <td>0.439899</td>\n",
       "      <td>16.146794</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.974945</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.436720</td>\n",
       "      <td>33.432083</td>\n",
       "      <td>3.436720</td>\n",
       "      <td>33.432083</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.974291</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.770787</td>\n",
       "      <td>30.861857</td>\n",
       "      <td>2.770787</td>\n",
       "      <td>30.861857</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.973938</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.257989</td>\n",
       "      <td>51.010804</td>\n",
       "      <td>4.257989</td>\n",
       "      <td>51.010804</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.973863</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.609156</td>\n",
       "      <td>214.566558</td>\n",
       "      <td>0.609156</td>\n",
       "      <td>214.566558</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.973155</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.069196</td>\n",
       "      <td>16.838439</td>\n",
       "      <td>4.069196</td>\n",
       "      <td>16.838439</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.972718</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.397800</td>\n",
       "      <td>10.268695</td>\n",
       "      <td>4.397800</td>\n",
       "      <td>10.268695</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.972588</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.449863</td>\n",
       "      <td>10.725438</td>\n",
       "      <td>4.449863</td>\n",
       "      <td>10.725438</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.972581</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.160010</td>\n",
       "      <td>17.583482</td>\n",
       "      <td>4.160010</td>\n",
       "      <td>17.583482</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.069196</td>\n",
       "      <td>16.838439</td>\n",
       "      <td>4.069196</td>\n",
       "      <td>16.838439</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.160010</td>\n",
       "      <td>17.583482</td>\n",
       "      <td>4.160010</td>\n",
       "      <td>17.583482</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.397800</td>\n",
       "      <td>10.268695</td>\n",
       "      <td>4.397800</td>\n",
       "      <td>10.268695</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>4.449863</td>\n",
       "      <td>10.725438</td>\n",
       "      <td>4.449863</td>\n",
       "      <td>10.725438</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.425326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.425326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.403707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.465805</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.058267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.058267</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.639776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.639776</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.516361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.516361</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.744808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.744808</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.553364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.553364</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_val eval_metric  pred_time_val  \\\n",
       "0            WeightedEnsemble_L2   0.976037     roc_auc      13.138355   \n",
       "1                CatBoost_BAG_L1   0.975710     roc_auc       1.599690   \n",
       "2                 XGBoost_BAG_L1   0.975152     roc_auc       0.439899   \n",
       "3              LightGBMXT_BAG_L1   0.974945     roc_auc       3.436720   \n",
       "4                LightGBM_BAG_L1   0.974291     roc_auc       2.770787   \n",
       "5           LightGBMLarge_BAG_L1   0.973938     roc_auc       4.257989   \n",
       "6          NeuralNetTorch_BAG_L1   0.973863     roc_auc       0.609156   \n",
       "7        RandomForestEntr_BAG_L1   0.973155     roc_auc       4.069196   \n",
       "8          ExtraTreesEntr_BAG_L1   0.972718     roc_auc       4.397800   \n",
       "9          ExtraTreesGini_BAG_L1   0.972588     roc_auc       4.449863   \n",
       "10       RandomForestGini_BAG_L1   0.972581     roc_auc       4.160010   \n",
       "11  RandomForestEntr_BAG_L1_FULL        NaN     roc_auc       4.069196   \n",
       "12  RandomForestGini_BAG_L1_FULL        NaN     roc_auc       4.160010   \n",
       "13    ExtraTreesEntr_BAG_L1_FULL        NaN     roc_auc       4.397800   \n",
       "14    ExtraTreesGini_BAG_L1_FULL        NaN     roc_auc       4.449863   \n",
       "15           XGBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "16      WeightedEnsemble_L2_FULL        NaN     roc_auc            NaN   \n",
       "17    NeuralNetTorch_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "18          LightGBM_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "19        LightGBMXT_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "20     LightGBMLarge_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "21          CatBoost_BAG_L1_FULL        NaN     roc_auc            NaN   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   443.156132                0.024113           5.465805            2   \n",
       "1    91.672231                1.599690          91.672231            1   \n",
       "2    16.146794                0.439899          16.146794            1   \n",
       "3    33.432083                3.436720          33.432083            1   \n",
       "4    30.861857                2.770787          30.861857            1   \n",
       "5    51.010804                4.257989          51.010804            1   \n",
       "6   214.566558                0.609156         214.566558            1   \n",
       "7    16.838439                4.069196          16.838439            1   \n",
       "8    10.268695                4.397800          10.268695            1   \n",
       "9    10.725438                4.449863          10.725438            1   \n",
       "10   17.583482                4.160010          17.583482            1   \n",
       "11   16.838439                4.069196          16.838439            1   \n",
       "12   17.583482                4.160010          17.583482            1   \n",
       "13   10.268695                4.397800          10.268695            1   \n",
       "14   10.725438                4.449863          10.725438            1   \n",
       "15    2.425326                     NaN           2.425326            1   \n",
       "16  105.403707                     NaN           5.465805            2   \n",
       "17   18.058267                     NaN          18.058267            1   \n",
       "18    2.639776                     NaN           2.639776            1   \n",
       "19    2.516361                     NaN           2.516361            1   \n",
       "20    3.744808                     NaN           3.744808            1   \n",
       "21   70.553364                     NaN          70.553364            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0       False         11  \n",
       "1       False          5  \n",
       "2       False          8  \n",
       "3       False          1  \n",
       "4       False          2  \n",
       "5       False         10  \n",
       "6       False          9  \n",
       "7        True          4  \n",
       "8        True          7  \n",
       "9        True          6  \n",
       "10       True          3  \n",
       "11       True         15  \n",
       "12       True         14  \n",
       "13       True         18  \n",
       "14       True         17  \n",
       "15       True         19  \n",
       "16       True         22  \n",
       "17       True         20  \n",
       "18       True         13  \n",
       "19       True         12  \n",
       "20       True         21  \n",
       "21       True         16  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b279b642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:39:31.833669Z",
     "iopub.status.busy": "2024-11-18T17:39:31.833415Z",
     "iopub.status.idle": "2024-11-18T17:39:37.275147Z",
     "shell.execute_reply": "2024-11-18T17:39:37.274243Z"
    },
    "papermill": {
     "duration": 5.492292,
     "end_time": "2024-11-18T17:39:37.277369",
     "exception": false,
     "start_time": "2024-11-18T17:39:31.785077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: AutogluonModels/ag-20241118_171021/models/CatBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMLarge_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/LightGBM_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/NeuralNetTorch_BAG_L1_FULL/model.pkl\n",
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/XGBoost_BAG_L1_FULL/model.pkl\n",
      "Loading: AutogluonModels/ag-20241118_171021/models/WeightedEnsemble_L2_FULL/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depression\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           1\n",
       "4           0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = predictor.predict(test).to_frame(name='Depression')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67e9b26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:39:37.381665Z",
     "iopub.status.busy": "2024-11-18T17:39:37.381084Z",
     "iopub.status.idle": "2024-11-18T17:39:37.413327Z",
     "shell.execute_reply": "2024-11-18T17:39:37.412395Z"
    },
    "papermill": {
     "duration": 0.083105,
     "end_time": "2024-11-18T17:39:37.415222",
     "exception": false,
     "start_time": "2024-11-18T17:39:37.332117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Depression\n",
       "0  140700           0\n",
       "1  140701           0\n",
       "2  140702           0\n",
       "3  140703           0\n",
       "4  140704           0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol=pd.read_csv('/kaggle/input/playground-series-s4e11/sample_submission.csv')\n",
    "sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77891c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:39:37.513520Z",
     "iopub.status.busy": "2024-11-18T17:39:37.513130Z",
     "iopub.status.idle": "2024-11-18T17:39:37.521324Z",
     "shell.execute_reply": "2024-11-18T17:39:37.520544Z"
    },
    "papermill": {
     "duration": 0.058046,
     "end_time": "2024-11-18T17:39:37.522987",
     "exception": false,
     "start_time": "2024-11-18T17:39:37.464941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Depression\n",
       "0  140700           0\n",
       "1  140701           0\n",
       "2  140702           0\n",
       "3  140703           1\n",
       "4  140704           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol['Depression']=df['Depression']\n",
    "sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645593d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:39:37.620750Z",
     "iopub.status.busy": "2024-11-18T17:39:37.620484Z",
     "iopub.status.idle": "2024-11-18T17:39:37.681536Z",
     "shell.execute_reply": "2024-11-18T17:39:37.680700Z"
    },
    "papermill": {
     "duration": 0.113061,
     "end_time": "2024-11-18T17:39:37.683125",
     "exception": false,
     "start_time": "2024-11-18T17:39:37.570064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sol.to_csv('./Autogluon_good_quality_gpu.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1819.513757,
   "end_time": "2024-11-18T17:39:42.949556",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T17:09:23.435799",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
