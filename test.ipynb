{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusion(y_val, y_pred):\n",
    "    # Assuming y_val and y_pred are defined\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def prediction_finale_split(modelS, modelP, X_trainS, y_trainS, X_trainP, y_trainP, X_testS, id_testS, X_testP, id_testP, oversamplingS = False, oversamplingP = False, threshold=0.5):\n",
    "    if oversamplingS:\n",
    "        smote = SMOTE()\n",
    "        X_trainS, y_trainS = smote.fit_resample(X_trainS, y_trainS)\n",
    "    if oversamplingP:\n",
    "        smote = SMOTE()\n",
    "        X_trainP, y_trainP = smote.fit_resample(X_trainP, y_trainP)\n",
    "    X_testS = X_testS.fillna(X_testS.median())\n",
    "    X_testP = X_testP.fillna(X_testP.median())\n",
    "    modelS.fit(X_trainS, y_trainS)\n",
    "    modelP.fit(X_trainP, y_trainP)\n",
    "    y_predS = modelS.predict(X_testS)\n",
    "    y_predP = modelP.predict(X_testP)\n",
    "    # y_predS = (y_predS > threshold).astype(int)\n",
    "    # y_predP = (y_predP > threshold).astype(int)\n",
    "    subS = pd.DataFrame({'id': id_testS, 'Depression': y_predS})\n",
    "    subP = pd.DataFrame({'id': id_testP, 'Depression': y_predP})\n",
    "\n",
    "    sub = pd.concat([subS, subP], axis=0)\n",
    "    sub = sub.sort_values(by='id')\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "def prediction_finale(model, X_train, y_train, X_test, id_test, oversampling = False, threshold=0.5):\n",
    "    if oversampling:\n",
    "        smote = SMOTE()\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    X_test = X_test.fillna(X_test.median())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # y_predS = (y_predS > threshold).astype(int)\n",
    "    # y_predP = (y_predP > threshold).astype(int)\n",
    "    sub = pd.DataFrame({'id': id_test, 'Depression': y_pred})\n",
    "\n",
    "    sub = sub.sort_values(by='id')\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    \n",
    "\n",
    "def test_model_split(modelS, modelP, X_trainS, y_trainS, X_trainP, y_trainP, oversamplingS = False, oversamplingP = False):\n",
    "    if oversamplingS:\n",
    "        smote = SMOTE()\n",
    "        X_trainS, y_trainS = smote.fit_resample(X_trainS, y_trainS)\n",
    "    if oversamplingP:\n",
    "        smote = SMOTE()\n",
    "        X_trainP, y_trainP = smote.fit_resample(X_trainP, y_trainP)\n",
    "    X_trainS, X_valS, y_trainS, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "    X_trainP, X_valP, y_trainP, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "    modelS.fit(X_trainS, y_trainS)\n",
    "    modelP.fit(X_trainP, y_trainP)\n",
    "    y_predS = modelS.predict(X_valS)\n",
    "    y_predP = modelP.predict(X_valP)\n",
    "    print('Model S')\n",
    "    print('Accuracy:', accuracy_score(y_valS, y_predS))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_valS, y_predS))\n",
    "    print('AUC:', roc_auc_score(y_valS, y_predS))\n",
    "    print('Model P')\n",
    "    print('Accuracy:', accuracy_score(y_valP, y_predP))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_valP, y_predP))\n",
    "    print('AUC:', roc_auc_score(y_valP, y_predP))\n",
    "    # confusion(y_valS, y_predS)\n",
    "    # confusion(y_valP, y_predP)\n",
    "\n",
    "    y_pred = np.concatenate((y_predS, y_predP))\n",
    "    y_val = np.concatenate((y_valS, y_valP))\n",
    "    print('Combined')\n",
    "    print('Accuracy:', accuracy_score(y_val, y_pred))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
    "    print('AUC:', roc_auc_score(y_val, y_pred)) \n",
    "\n",
    "\n",
    "def test_model(model, X_train, y_train, oversampling = False):\n",
    "    if oversampling:\n",
    "        smote = SMOTE()\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "   \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    print('Combined')\n",
    "    print('Accuracy:', accuracy_score(y_val, y_pred))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
    "    print('AUC:', roc_auc_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "    Val = X_val\n",
    "    Val['label'] = y_val\n",
    "    Val_S = Val[Val['Profession_Student'] == 1]\n",
    "    Val_P = Val[Val['Profession_Student'] == 0]\n",
    "    y_valS = Val_S['label']\n",
    "    y_valP = Val_P['label']\n",
    "    X_valS = Val_S.drop(columns=['label'])\n",
    "    X_valP = Val_P.drop(columns=['label'])\n",
    "\n",
    "    Pred = X_val\n",
    "    Pred['label'] = y_pred\n",
    "    Pred_S = Pred[Pred['Profession_Student'] == 1]\n",
    "    Pred_P = Pred[Pred['Profession_Student'] == 0]\n",
    "    y_predS = Pred_S['label']\n",
    "    y_predP = Pred_P['label']\n",
    "    X_predS = Pred_S.drop(columns=['label'])\n",
    "    X_predP = Pred_P.drop(columns=['label'])\n",
    "\n",
    "\n",
    "\n",
    "    print('Students')\n",
    "    print('Accuracy:', accuracy_score(y_valS, y_predS))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_valS, y_predS))\n",
    "    print('AUC:', roc_auc_score(y_valS, y_predS))\n",
    "    print('Professionals')\n",
    "    print('Accuracy:', accuracy_score(y_valP, y_predP))\n",
    "    print('Balanced accuracy:', balanced_accuracy_score(y_valP, y_predP))\n",
    "    print('AUC:', roc_auc_score(y_valP, y_predP))\n",
    "    # confusion(y_valS, y_predS)\n",
    "    # confusion(y_valP, y_predP)\n",
    "\n",
    "   \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_train: 140700\n",
      "len_test: 93800\n",
      "len_X: 234500\n"
     ]
    }
   ],
   "source": [
    "def preprocess_all_data(train, test, split=False):\n",
    "\n",
    "\n",
    "    X_train = train.drop('Depression', axis=1)\n",
    "    y_train = train['Depression']\n",
    "    X = pd.concat([X_train, test], axis=0)\n",
    "    len_train = len(X_train)\n",
    "    len_test = len(test)\n",
    "    len_X = len(X)\n",
    "    print('len_train:', len_train)\n",
    "    print('len_test:', len_test)\n",
    "    print('len_X:', len_X)\n",
    "\n",
    "\n",
    "    if split:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X = X.drop(['Name'], axis=1)\n",
    "        X['Pressure'] = X[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "        X = X.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "        X['Gender'] = (X['Gender'] == 'Male').astype(int)\n",
    "        X.loc[X['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "        X['Satisfaction'] = X[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "        X = X.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "        X['Family History of Mental Illness'] = (X['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "        X['Have you ever had suicidal thoughts ?'] = (X['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "\n",
    "\n",
    "        X = X.drop(['City'], axis=1)\n",
    "\n",
    "\n",
    "        # v = X[\"City\"].value_counts() \n",
    "        # tmp = X[X['City'].isin(v.index[v.gt(10)])]\n",
    "        # tmp = pd.get_dummies(tmp, columns=['City'])\n",
    "        # tmp_cols = [col for col in tmp.columns if col.startswith('City_')]\n",
    "        # X = pd.get_dummies(X, columns=['City'])\n",
    "        # City_cols = [col for col in X.columns if col.startswith('City_')]\n",
    "        # X[City_cols] = X[City_cols].astype(int)\n",
    "        # X = X.drop(tmp_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "        X['Dietary Habits'] = X['Dietary Habits'].map(diet_mapping)\n",
    "        v = X[\"Profession\"].value_counts() \n",
    "\n",
    "        X = pd.get_dummies(X, columns=['Profession'])\n",
    "        profession_cols = [col for col in X.columns if col.startswith('Profession_')]\n",
    "        X[profession_cols] = X[profession_cols].astype(int)\n",
    "        X = X.drop(['Working Professional or Student'], axis=1)\n",
    "        v = X[\"Degree\"].value_counts() \n",
    "        X = pd.get_dummies(X, columns=['Degree'])\n",
    "        degree_cols = [col for col in X.columns if col.startswith('Degree_')]\n",
    "        X[degree_cols] = X[degree_cols].astype(int)\n",
    "        dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "        X['Sleep Duration'] = X['Sleep Duration'].map(dict_sleep)\n",
    "        X['CGPA'] = X['CGPA'].fillna(X['CGPA'].mean())\n",
    "\n",
    "        X_train = X[:len_train]\n",
    "        X_test = X[len_train:]\n",
    "\n",
    "        X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "        X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "        X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "        X_trainP = X_trainP.drop(['CGPA'], axis=1)\n",
    "        X_trainS = X_trainS.drop(profession_cols, axis=1)\n",
    "\n",
    "        X_testS = X_test[X_test['Profession_Student'] == 1]\n",
    "        X_testP = X_test[X_test['Profession_Student'] == 0]\n",
    "        X_testP = X_testP.drop(['Profession_Student'], axis=1)\n",
    "        X_testP = X_testP.drop(['CGPA'], axis=1)\n",
    "        X_testS = X_testS.drop(profession_cols, axis=1)\n",
    "        \n",
    "\n",
    "        y_trainS = y_train[X_trainS.index]\n",
    "        y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "        id_testS = X_testS['id']\n",
    "        id_testP = X_testP['id']\n",
    "        X_trainS = X_trainS.drop(['id'], axis=1)\n",
    "        X_trainP = X_trainP.drop(['id'], axis=1)\n",
    "        X_testS = X_testS.drop(['id'], axis=1)\n",
    "        X_testP = X_testP.drop(['id'], axis=1)\n",
    "\n",
    "        train_S = pd.concat([X_trainS, y_trainS], axis=1)\n",
    "        train_S = train_S.dropna()\n",
    "        X_trainS = train_S.drop('Depression', axis=1)\n",
    "        y_trainS = train_S['Depression']\n",
    "\n",
    "        train_P = pd.concat([X_trainP, y_trainP], axis=1)\n",
    "        train_P = train_P.dropna()\n",
    "        X_trainP = train_P.drop('Depression', axis=1)\n",
    "        y_trainP = train_P['Depression']\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return X_trainS, y_trainS, X_trainP, y_trainP, X_testS, id_testS, X_testP, id_testP\n",
    "\n",
    "\n",
    "\n",
    "    else :\n",
    "        X = X.drop(['Name'], axis=1)\n",
    "        X['Pressure'] = X[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "        X = X.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "        X['Gender'] = (X['Gender'] == 'Male').astype(int)\n",
    "        X.loc[X['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "        X['Satisfaction'] = X[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "        X = X.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "        X['Family History of Mental Illness'] = (X['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "        X['Have you ever had suicidal thoughts ?'] = (X['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "\n",
    "\n",
    "        X = X.drop(['City'], axis=1)\n",
    "\n",
    "\n",
    "        # v = X[\"City\"].value_counts() \n",
    "        # tmp = X[X['City'].isin(v.index[v.gt(10)])]\n",
    "        # tmp = pd.get_dummies(tmp, columns=['City'])\n",
    "        # tmp_cols = [col for col in tmp.columns if col.startswith('City_')]\n",
    "        # X = pd.get_dummies(X, columns=['City'])\n",
    "        # City_cols = [col for col in X.columns if col.startswith('City_')]\n",
    "        # X[City_cols] = X[City_cols].astype(int)\n",
    "        # X = X.drop(tmp_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "        X['Dietary Habits'] = X['Dietary Habits'].map(diet_mapping)\n",
    "        v = X[\"Profession\"].value_counts() \n",
    "\n",
    "        X = pd.get_dummies(X, columns=['Profession'])\n",
    "        profession_cols = [col for col in X.columns if col.startswith('Profession_')]\n",
    "        X[profession_cols] = X[profession_cols].astype(int)\n",
    "        X = X.drop(['Working Professional or Student'], axis=1)\n",
    "        v = X[\"Degree\"].value_counts() \n",
    "        X = pd.get_dummies(X, columns=['Degree'])\n",
    "        degree_cols = [col for col in X.columns if col.startswith('Degree_')]\n",
    "        X[degree_cols] = X[degree_cols].astype(int)\n",
    "        dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "        X['Sleep Duration'] = X['Sleep Duration'].map(dict_sleep)\n",
    "        X['CGPA'] = X['CGPA'].fillna(X['CGPA'].mean())\n",
    "\n",
    "        X_train = X[:len_train]\n",
    "        X_test = X[len_train:]\n",
    "        X_train = X_train.drop(['id'], axis=1)\n",
    "        id_test = X_test['id']\n",
    "        X_test = X_test.drop(['id'], axis=1)\n",
    "\n",
    "        train = pd.concat([X_train, y_train], axis=1)\n",
    "        train = train.dropna()\n",
    "        X_train = train.drop('Depression', axis=1)\n",
    "        y_train = train['Depression']\n",
    "\n",
    "\n",
    "        return X_train, X_test, y_train, id_test\n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, id_test = preprocess_all_data(train, test, split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "# test = pd.read_csv('test.csv')\n",
    "\n",
    "# X_train = train.drop('Depression', axis=1)\n",
    "# y_train = train['Depression']\n",
    "# X = pd.concat([X_train, test], axis=0)\n",
    "# len_train = len(X_train)\n",
    "# len_test = len(test)\n",
    "# len_X = len(X)\n",
    "# print('len_train:', len_train)\n",
    "# print('len_test:', len_test)\n",
    "# print('len_X:', len_X)\n",
    "\n",
    "\n",
    "\n",
    "# X = X.drop(['Name'], axis=1)\n",
    "# X['Pressure'] = X[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "# X = X.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "# X['Gender'] = (X['Gender'] == 'Male').astype(int)\n",
    "# X.loc[X['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "# X['Satisfaction'] = X[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "# X = X.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "# X['Family History of Mental Illness'] = (X['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "# X['Have you ever had suicidal thoughts ?'] = (X['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "\n",
    "\n",
    "# X = X.drop(['City'], axis=1)\n",
    "\n",
    "\n",
    "# # v = X[\"City\"].value_counts() \n",
    "# # tmp = X[X['City'].isin(v.index[v.gt(10)])]\n",
    "# # tmp = pd.get_dummies(tmp, columns=['City'])\n",
    "# # tmp_cols = [col for col in tmp.columns if col.startswith('City_')]\n",
    "# # X = pd.get_dummies(X, columns=['City'])\n",
    "# # City_cols = [col for col in X.columns if col.startswith('City_')]\n",
    "# # X[City_cols] = X[City_cols].astype(int)\n",
    "# # X = X.drop(tmp_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "# X['Dietary Habits'] = X['Dietary Habits'].map(diet_mapping)\n",
    "# v = X[\"Profession\"].value_counts() \n",
    "\n",
    "# X = pd.get_dummies(X, columns=['Profession'])\n",
    "# profession_cols = [col for col in X.columns if col.startswith('Profession_')]\n",
    "# X[profession_cols] = X[profession_cols].astype(int)\n",
    "# X = X.drop(['Working Professional or Student'], axis=1)\n",
    "# v = X[\"Degree\"].value_counts() \n",
    "# X = pd.get_dummies(X, columns=['Degree'])\n",
    "# degree_cols = [col for col in X.columns if col.startswith('Degree_')]\n",
    "# X[degree_cols] = X[degree_cols].astype(int)\n",
    "# dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "# X['Sleep Duration'] = X['Sleep Duration'].map(dict_sleep)\n",
    "# X['CGPA'] = X['CGPA'].fillna(X['CGPA'].mean())\n",
    "\n",
    "# X_train = X[:len_train]\n",
    "# X_test = X[len_train:]\n",
    "\n",
    "# X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "# X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "# X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "# X_trainP = X_trainP.drop(['CGPA'], axis=1)\n",
    "# X_trainS = X_trainS.drop(profession_cols, axis=1)\n",
    "\n",
    "# X_testS = X_test[X_test['Profession_Student'] == 1]\n",
    "# X_testP = X_test[X_test['Profession_Student'] == 0]\n",
    "# X_testP = X_testP.drop(['Profession_Student'], axis=1)\n",
    "# X_testP = X_testP.drop(['CGPA'], axis=1)\n",
    "# X_testS = X_testS.drop(profession_cols, axis=1)\n",
    "\n",
    "# X_trainSS = X_train.drop(profession_cols, axis=1)\n",
    "# X_trainSS = X_trainSS.drop(['id'], axis=1)\n",
    "# X_trainPP = X_train.drop(['Profession_Student'], axis=1)\n",
    "# X_trainPP = X_trainPP.drop(['CGPA'], axis=1)\n",
    "# X_trainPP = X_trainPP.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "# y_trainS = y_train[X_trainS.index]\n",
    "# y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "# id_testS = X_testS['id']\n",
    "# id_testP = X_testP['id']\n",
    "# X_trainS = X_trainS.drop(['id'], axis=1)\n",
    "# X_trainP = X_trainP.drop(['id'], axis=1)\n",
    "# X_testS = X_testS.drop(['id'], axis=1)\n",
    "# X_testP = X_testP.drop(['id'], axis=1)\n",
    "\n",
    "# train_S = pd.concat([X_trainS, y_trainS], axis=1)\n",
    "# train_S = train_S.dropna()\n",
    "# X_trainS = train_S.drop('Depression', axis=1)\n",
    "# y_trainS = train_S['Depression']\n",
    "\n",
    "# train_P = pd.concat([X_trainP, y_trainP], axis=1)\n",
    "# train_P = train_P.dropna()\n",
    "# X_trainP = train_P.drop('Depression', axis=1)\n",
    "# y_trainP = train_P['Depression']\n",
    "\n",
    "# trainSS = pd.concat([X_trainSS, y_train], axis=1)\n",
    "# trainSS = trainSS.dropna()\n",
    "# X_trainSS = trainSS.drop('Depression', axis=1)\n",
    "# y_trainSS = trainSS['Depression']\n",
    "\n",
    "# trainPP = pd.concat([X_trainPP, y_train], axis=1)\n",
    "# trainPP = trainPP.dropna()\n",
    "# X_trainPP = trainPP.drop('Depression', axis=1)\n",
    "# y_trainPP = trainPP['Depression']\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sans Oversampling\n",
      "Combined\n",
      "Accuracy: 0.9371977240398293\n",
      "Balanced accuracy: 0.887941334559768\n",
      "AUC: 0.887941334559768\n",
      "Students\n",
      "Accuracy: 0.8467986445514536\n",
      "Balanced accuracy: 0.8379361565243717\n",
      "AUC: 0.8379361565243717\n",
      "Professionals\n",
      "Accuracy: 0.9597121663039133\n",
      "Balanced accuracy: 0.8304089976680162\n",
      "AUC: 0.8304089976680162\n",
      "Avec Oversampling\n",
      "Combined\n",
      "Accuracy: 0.950722433460076\n",
      "Balanced accuracy: 0.9506666359896718\n",
      "AUC: 0.9506666359896718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200534/3865434980.py:84: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Val['label'] = y_val\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students\n",
      "Accuracy: 0.9334065799914546\n",
      "Balanced accuracy: 0.8363907484235522\n",
      "AUC: 0.8363907484235522\n",
      "Professionals\n",
      "Accuracy: 0.9602928277444167\n",
      "Balanced accuracy: 0.9523258073607664\n",
      "AUC: 0.9523258073607664\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1, max_iter=100, penalty ='l1', solver = 'liblinear')\n",
    "# Sans Oversampling\n",
    "print ('Sans Oversampling')\n",
    "test_model(model, X_train, y_train, oversampling = False)\n",
    "\n",
    "# Avec Oversampling\n",
    "print ('Avec Oversampling')\n",
    "test_model(model, X_train, y_train, oversampling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_train: 140700\n",
      "len_test: 93800\n",
      "len_X: 234500\n",
      "Sans Oversampling\n",
      "Model S\n",
      "Accuracy: 0.846457399103139\n",
      "Balanced accuracy: 0.8390055722019462\n",
      "AUC: 0.8390055722019462\n",
      "Model P\n",
      "Accuracy: 0.9607025636476537\n",
      "Balanced accuracy: 0.8371604536198967\n",
      "AUC: 0.8371604536198967\n",
      "Combined\n",
      "Accuracy: 0.9380534120408236\n",
      "Balanced accuracy: 0.8893272431654513\n",
      "AUC: 0.8893272431654514\n",
      "Avec Oversampling\n",
      "Model S\n",
      "Accuracy: 0.8775854144323579\n",
      "Balanced accuracy: 0.8775941450604887\n",
      "AUC: 0.8775941450604887\n",
      "Model P\n",
      "Accuracy: 0.9769334814743249\n",
      "Balanced accuracy: 0.976939127924269\n",
      "AUC: 0.9769391279242688\n",
      "Combined\n",
      "Accuracy: 0.9634042020488639\n",
      "Balanced accuracy: 0.9634046717620951\n",
      "AUC: 0.9634046717620951\n"
     ]
    }
   ],
   "source": [
    "modelS = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "modelP = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "# Sans Oversampling\n",
    "X_trainS, y_trainS, X_trainP, y_trainP, X_testS, id_testS, X_testP, id_testP = preprocess_all_data(train, test, split=True)\n",
    "print ('Sans Oversampling')\n",
    "test_model_split(modelS, modelP, X_trainS, y_trainS, X_trainP, y_trainP, oversamplingS = False, oversamplingP = False)\n",
    "\n",
    "# Avec Oversampling\n",
    "print ('Avec Oversampling')\n",
    "test_model_split(modelS, modelP, X_trainS, y_trainS, X_trainP, y_trainP, oversamplingS = True, oversamplingP = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model S\n",
      "Accuracy: 0.8466367713004485\n",
      "Balanced accuracy: 0.839814853725404\n",
      "AUC: 0.839814853725404\n",
      "Model P\n",
      "Accuracy: 0.9607025636476537\n",
      "Balanced accuracy: 0.8371604536198967\n",
      "AUC: 0.8371604536198967\n",
      "Combined\n",
      "Accuracy: 0.9380889726538886\n",
      "Balanced accuracy: 0.8885924092024939\n",
      "AUC: 0.8885924092024939\n"
     ]
    }
   ],
   "source": [
    "modelS = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "modelP = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "\n",
    "\n",
    "X_trainS, X_valS, y_trainS, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "X_train_filteredS = X_trainSS[~X_trainSS.index.isin(X_valS.index)]\n",
    "y_train_filteredS = y_trainSS[~y_trainSS.index.isin(y_valS.index)]\n",
    "X_trainP, X_valP, y_trainP, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "modelS.fit(X_train_filteredS, y_train_filteredS)\n",
    "modelP.fit(X_trainP, y_trainP)\n",
    "y_predS = modelS.predict(X_valS)\n",
    "y_predP = modelP.predict(X_valP)\n",
    "print('Model S')\n",
    "print('Accuracy:', accuracy_score(y_valS, y_predS))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(y_valS, y_predS))\n",
    "print('AUC:', roc_auc_score(y_valS, y_predS))\n",
    "print('Model P')\n",
    "print('Accuracy:', accuracy_score(y_valP, y_predP))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(y_valP, y_predP))\n",
    "print('AUC:', roc_auc_score(y_valP, y_predP))\n",
    "# confusion(y_valS, y_predS)\n",
    "# confusion(y_valP, y_predP)\n",
    "\n",
    "y_pred = np.concatenate((y_predS, y_predP))\n",
    "y_val = np.concatenate((y_valS, y_valP))\n",
    "print('Combined')\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(y_val, y_pred))\n",
    "print('AUC:', roc_auc_score(y_val, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model S\n",
      "Accuracy: 0.9380867709815078\n",
      "Balanced accuracy: 0.8906360702578742\n",
      "AUC: 0.8906360702578742\n",
      "Model P\n",
      "Accuracy: 0.9607025636476537\n",
      "Balanced accuracy: 0.8371604536198967\n",
      "AUC: 0.8371604536198967\n",
      "Combined\n",
      "Accuracy: 0.948150633560968\n",
      "Balanced accuracy: 0.8784134157368149\n",
      "AUC: 0.8784134157368149\n"
     ]
    }
   ],
   "source": [
    "# Best Gradient Boosting parameters: {'learning_rate': 0.3, 'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 200, 'subsample': 1.0}\n",
    "\n",
    "gbS = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "gbP = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "\n",
    "test_model(gbS, gbP, X_trainS, y_trainS, X_trainP, y_trainP, oversamplingS=False, oversamplingP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbS = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "gbP = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0)\n",
    "# Droping Professions\n",
    "prediction_finale(gbS, gbP, X_trainS, y_trainS, X_trainP, y_trainP, X_testS, id_testS, X_testP, id_testP, oversamplingS=False, oversamplingP=False, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9385490753911807\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = train.drop('Depression', axis=1)\n",
    "y_train = train['Depression']\n",
    "X = pd.concat([X_train, test], axis=0)\n",
    "len_train = len(X_train)\n",
    "len_test = len(test)\n",
    "len_X = len(X)\n",
    "\n",
    "\n",
    "#X = X.drop(['id', 'Name'], axis=1)\n",
    "X = X.drop(['Name'], axis=1)\n",
    "X['Pressure'] = X[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "X = X.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "X['Gender'] = (X['Gender'] == 'Male').astype(int)\n",
    "X.loc[X['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "X['Satisfaction'] = X[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "X = X.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "X['Family History of Mental Illness'] = (X['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "X['Have you ever had suicidal thoughts ?'] = (X['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "\n",
    "\n",
    "X = X.drop(['City'], axis=1)\n",
    "\n",
    "\n",
    "# v = X[\"City\"].value_counts() \n",
    "# tmp = X[X['City'].isin(v.index[v.gt(50)])]\n",
    "# tmp = pd.get_dummies(tmp, columns=['City'])\n",
    "# tmp_cols = [col for col in tmp.columns if col.startswith('City_')]\n",
    "# X = pd.get_dummies(X, columns=['City'])\n",
    "# City_cols = [col for col in X.columns if col.startswith('City_')]\n",
    "# X[City_cols] = X[City_cols].astype(int)\n",
    "# X = X.drop(tmp_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "X['Dietary Habits'] = X['Dietary Habits'].map(diet_mapping)\n",
    "v = X[\"Profession\"].value_counts() \n",
    "\n",
    "X = pd.get_dummies(X, columns=['Profession'])\n",
    "profession_cols = [col for col in X.columns if col.startswith('Profession_')]\n",
    "X[profession_cols] = X[profession_cols].astype(int)\n",
    "prof_counts = X[profession_cols].sum()\n",
    "remove_cols = prof_counts[prof_counts <= 20].index\n",
    "\n",
    "X = X.drop(remove_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X = X.drop(['Working Professional or Student'], axis=1)\n",
    "v = X[\"Degree\"].value_counts() \n",
    "X = pd.get_dummies(X, columns=['Degree'])\n",
    "degree_cols = [col for col in X.columns if col.startswith('Degree_')]\n",
    "X[degree_cols] = X[degree_cols].astype(int)\n",
    "\n",
    "degree_counts = X[degree_cols].sum()\n",
    "remove_cols = degree_counts[degree_counts <= 20].index\n",
    "\n",
    "X = X.drop(remove_cols, axis=1)\n",
    "\n",
    "dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "X['Sleep Duration'] = X['Sleep Duration'].map(dict_sleep)\n",
    "\n",
    "# todo after the split\n",
    "X['CGPA'] = X['CGPA'].fillna(X['CGPA'].median())\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train = X[:len_train]\n",
    "X_test = X[len_train:]\n",
    "X_train = X_train.drop(['id'], axis=1)\n",
    "id_test = X_test['id']\n",
    "X_test = X_test.drop(['id'], axis=1)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train = train.dropna()\n",
    "X_train = train.drop('Depression', axis=1)\n",
    "y_train = train['Depression']\n",
    "\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0, random_state=42)\n",
    "\n",
    "gb.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = gb.predict(X_val)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9388361428663695\n",
      "Accuracy: 0.9393052148452956\n"
     ]
    }
   ],
   "source": [
    "# get only the Gender = 1\n",
    "X_trainM = X_train[X_train['Gender'] == 1]\n",
    "X_trainF = X_train[X_train['Gender'] == 0]\n",
    "y_trainM = y_train[X_trainM.index]\n",
    "y_trainF = y_train[X_trainF.index]\n",
    "\n",
    "X_trainM, X_valM, y_trainM, y_valM = train_test_split(X_trainM, y_trainM, test_size=0.2, random_state=42)\n",
    "X_trainF, X_valF, y_trainF, y_valF = train_test_split(X_trainF, y_trainF, test_size=0.2, random_state=42)\n",
    "\n",
    "gb.fit(X_trainM, y_trainM)\n",
    "y_predM = gb.predict(X_valM)\n",
    "print('Accuracy:', accuracy_score(y_valM, y_predM))\n",
    "\n",
    "gb.fit(X_trainF, y_trainF)\n",
    "y_predF = gb.predict(X_valF)\n",
    "print('Accuracy:', accuracy_score(y_valF, y_predF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9421835851491914\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(train):\n",
    "    train = train.drop(['id', 'Name'], axis=1)\n",
    "    train['Pressure'] = train[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "    train = train.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "    # encode gender in 1 and 0 (1 for male and 0 for Female)\n",
    "    train['Gender'] = (train['Gender'] == 'Male').astype(int)\n",
    "    # For Working Status (Student = 0, Working Professional = 1)\n",
    "    # train['Working Professional or Student'] = (train['Working Professional or Student'] == 'Working Professional').astype(int)\n",
    "    train.loc[train['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "    train['Satisfaction'] = train[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "    train = train.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "    train['Family History of Mental Illness'] = (train['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "    train['Have you ever had suicidal thoughts ?'] = (train['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "    # we can either drop City or encode it in one hot encoding\n",
    "    # one hot encoding\n",
    "    #train = pd.get_dummies(train, columns=['City']).astype(int)\n",
    "    # drop city\n",
    "    train = train.drop(['City'], axis=1)\n",
    "    diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "    train = train[train['Dietary Habits'].isin(diet_mapping.keys())]\n",
    "    train['Dietary Habits'] = train['Dietary Habits'].map(diet_mapping)\n",
    "    v = train[\"Profession\"].value_counts() \n",
    "    # keep only the profession with more than 10 samples\n",
    "    train = train[train['Profession'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Profession'])\n",
    "    profession_cols = [col for col in train.columns if col.startswith('Profession_')]\n",
    "    train[profession_cols] = train[profession_cols].astype(int)\n",
    "    train = train.drop(['Working Professional or Student'], axis=1)\n",
    "    v = train[\"Degree\"].value_counts() \n",
    "    train = train[train['Degree'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Degree'])\n",
    "    degree_cols = [col for col in train.columns if col.startswith('Degree_')]\n",
    "    train[degree_cols] = train[degree_cols].astype(int)\n",
    "    dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "    train = train[train['Sleep Duration'].isin(dict_sleep.keys())]\n",
    "    train['Sleep Duration'] = train['Sleep Duration'].map(dict_sleep)\n",
    "    train['CGPA'] = train['CGPA'].fillna(train['CGPA'].mean())\n",
    "    train = train.dropna()\n",
    "    return train\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train = preprocess_data(train)\n",
    "X_train = train.drop('Depression', axis=1)\n",
    "y_train = train['Depression']\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.3, max_depth=3, min_samples_split=4, n_estimators=200, subsample=1.0, random_state=42)\n",
    "\n",
    "gb.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = gb.predict(X_val)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
