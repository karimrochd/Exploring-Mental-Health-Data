{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train):\n",
    "    train = train.drop(['id', 'Name'], axis=1)\n",
    "    train['Pressure'] = train[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "    train = train.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "    # encode gender in 1 and 0 (1 for male and 0 for Female)\n",
    "    train['Gender'] = (train['Gender'] == 'Male').astype(int)\n",
    "    # For Working Status (Student = 0, Working Professional = 1)\n",
    "    # train['Working Professional or Student'] = (train['Working Professional or Student'] == 'Working Professional').astype(int)\n",
    "    train.loc[train['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "    train['Satisfaction'] = train[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "    train = train.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "    train['Family History of Mental Illness'] = (train['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "    train['Have you ever had suicidal thoughts ?'] = (train['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "    # we can either drop City or encode it in one hot encoding\n",
    "    # one hot encoding\n",
    "    #train = pd.get_dummies(train, columns=['City']).astype(int)\n",
    "    # drop city\n",
    "    train = train.drop(['City'], axis=1)\n",
    "    diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "    #todo train = train[train['Dietary Habits'].isin(diet_mapping.keys())]\n",
    "    train['Dietary Habits'] = train['Dietary Habits'].map(diet_mapping)\n",
    "    v = train[\"Profession\"].value_counts() \n",
    "    # keep only the profession with more than 10 samples\n",
    "    #todo train = train[train['Profession'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Profession'])\n",
    "    profession_cols = [col for col in train.columns if col.startswith('Profession_')]\n",
    "    train[profession_cols] = train[profession_cols].astype(int)\n",
    "    train = train.drop(['Working Professional or Student'], axis=1)\n",
    "    v = train[\"Degree\"].value_counts() \n",
    "    #todo train = train[train['Degree'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Degree'])\n",
    "    degree_cols = [col for col in train.columns if col.startswith('Degree_')]\n",
    "    train[degree_cols] = train[degree_cols].astype(int)\n",
    "    dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "    #todo train = train[train['Sleep Duration'].isin(dict_sleep.keys())]\n",
    "    train['Sleep Duration'] = train['Sleep Duration'].map(dict_sleep)\n",
    "    train['CGPA'] = train['CGPA'].fillna(train['CGPA'].mean())\n",
    "    #train = train.dropna()\n",
    "    return train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_index(train):\n",
    "    train = train.drop(['id', 'Name'], axis=1)\n",
    "    train['Pressure'] = train[['Work Pressure', 'Academic Pressure']].max(axis=1)\n",
    "    train = train.drop(['Work Pressure', 'Academic Pressure'], axis=1)\n",
    "    # encode gender in 1 and 0 (1 for male and 0 for Female)\n",
    "    train['Gender'] = (train['Gender'] == 'Male').astype(int)\n",
    "    # For Working Status (Student = 0, Working Professional = 1)\n",
    "    # train['Working Professional or Student'] = (train['Working Professional or Student'] == 'Working Professional').astype(int)\n",
    "    train.loc[train['Working Professional or Student'] == 'Student', 'Profession'] = 'Student'\n",
    "    train['Satisfaction'] = train[['Study Satisfaction', 'Job Satisfaction']].max(axis=1)\n",
    "    train = train.drop(['Study Satisfaction', 'Job Satisfaction'], axis=1)\n",
    "    train['Family History of Mental Illness'] = (train['Family History of Mental Illness'] == 'Yes').astype(int)\n",
    "    train['Have you ever had suicidal thoughts ?'] = (train['Have you ever had suicidal thoughts ?'] == 'Yes').astype(int)\n",
    "    # we can either drop City or encode it in one hot encoding\n",
    "    # one hot encoding\n",
    "    #train = pd.get_dummies(train, columns=['City']).astype(int)\n",
    "    # drop city\n",
    "    train = train.drop(['City'], axis=1)\n",
    "    diet_mapping = {'Moderate': 1.0, 'Unhealthy': 0.0, 'Healthy': 2.0}\n",
    "    train = train[train['Dietary Habits'].isin(diet_mapping.keys())]\n",
    "    train['Dietary Habits'] = train['Dietary Habits'].map(diet_mapping)\n",
    "    v = train[\"Profession\"].value_counts() \n",
    "    # keep only the profession with more than 10 samples\n",
    "    train = train[train['Profession'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Profession'])\n",
    "    profession_cols = [col for col in train.columns if col.startswith('Profession_')]\n",
    "    train[profession_cols] = train[profession_cols].astype(int)\n",
    "    train = train.drop(['Working Professional or Student'], axis=1)\n",
    "    v = train[\"Degree\"].value_counts() \n",
    "    train = train[train['Degree'].isin(v.index[v.gt(10)])]\n",
    "    # one hot encoding\n",
    "    train = pd.get_dummies(train, columns=['Degree'])\n",
    "    degree_cols = [col for col in train.columns if col.startswith('Degree_')]\n",
    "    train[degree_cols] = train[degree_cols].astype(int)\n",
    "    dict_sleep = {'Less than 5 hours': 4.0, '5-6 hours': 5.5, '6-7 hours': 6.5, '7-8 hours': 7.5, 'More than 8 hours': 9.0, '2-3 hours': 2.5, '3-4 hours': 3.5, '4-5 hours': 4.5, '4-6 hours': 5.0}\n",
    "    train = train[train['Sleep Duration'].isin(dict_sleep.keys())]\n",
    "    train['Sleep Duration'] = train['Sleep Duration'].map(dict_sleep)\n",
    "    train['CGPA'] = train['CGPA'].fillna(train['CGPA'].mean())\n",
    "    train = train.dropna()\n",
    "    return train.index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131707\n",
      "93800\n",
      "225507\n",
      "225507\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X_train = train.drop('Depression', axis=1)\n",
    "X_train_index = preprocess_data_index(X_train)\n",
    "X_train = X_train.loc[X_train_index]\n",
    "y_train = train['Depression']\n",
    "len_train = len(X_train)\n",
    "len_test = len(test)\n",
    "print(len_train)\n",
    "print(len_test)\n",
    "X = pd.concat([X_train, test], axis=0)\n",
    "print(len(X))\n",
    "X = preprocess_data(X)\n",
    "print(len(X))\n",
    "\n",
    "X_train = X[:len_train]\n",
    "X_test = X[len_train:]\n",
    "X_test = X_test.fillna(X_test.mean())\n",
    "\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "train = train.dropna()\n",
    "X_train = train.drop('Depression', axis=1)\n",
    "y_train = train['Depression']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a min max scaling of the data for the columns that are not one hot encoded\n",
    "scaler = MinMaxScaler()\n",
    "columns = ['Age', 'CGPA', 'Pressure', 'Satisfaction', 'Sleep Duration']\n",
    "X_train[columns] = scaler.fit_transform(X_train[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5346818\ttotal: 43.1ms\tremaining: 8.58s\n",
      "100:\tlearn: 0.1394388\ttotal: 799ms\tremaining: 783ms\n",
      "199:\tlearn: 0.1352191\ttotal: 1.54s\tremaining: 0us\n",
      "Accuracy: 0.9426011692354415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = catboost = CatBoostClassifier(iterations=200, depth=5, learning_rate=0.1, loss_function='Logloss', verbose=100, l2_leaf_reg= 1)\n",
    "\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier :  {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
    "xgb = XGBClassifier(colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "# catboost {'depth': 4, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.2}\n",
    "catboost = CatBoostClassifier(iterations=200, depth=4, learning_rate=0.2, loss_function='Logloss', verbose=100, l2_leaf_reg= 5)\n",
    "# GradientBoostingClassifier:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
    "gb = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "# Best parameters for LogisticRegression:  {'C': 100, 'l1_ratio': None, 'max_iter': 10000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "lr = LogisticRegression(C=100, l1_ratio=None, max_iter=10000, penalty='l1', solver='liblinear')\n",
    "\n",
    "estimators = [('xgb', xgb), ('catboost', catboost), ('gb', gb), ('lr', lr)]\n",
    "\n",
    "\n",
    "vote = VotingClassifier(estimators=estimators, voting='hard')\n",
    "\n",
    "# vote.fit(X_train2, y_train2)\n",
    "\n",
    "# y_pred = vote.predict(X_val)\n",
    "\n",
    "\n",
    "# print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4184337\ttotal: 18.5ms\tremaining: 3.68s\n",
      "100:\tlearn: 0.1392964\ttotal: 743ms\tremaining: 729ms\n",
      "199:\tlearn: 0.1358195\ttotal: 1.45s\tremaining: 0us\n",
      "Accuracy for male: 0.9435511696915326\n",
      "0:\tlearn: 0.4175761\ttotal: 16.9ms\tremaining: 3.36s\n",
      "100:\tlearn: 0.1385169\ttotal: 715ms\tremaining: 701ms\n",
      "199:\tlearn: 0.1351267\ttotal: 1.42s\tremaining: 0us\n",
      "Accuracy for female: 0.9408488735127837\n",
      "Accuracy combined: 0.9423354339078278\n",
      "0:\tlearn: 0.5346818\ttotal: 12.2ms\tremaining: 2.42s\n",
      "100:\tlearn: 0.1394388\ttotal: 732ms\tremaining: 717ms\n",
      "199:\tlearn: 0.1352191\ttotal: 1.44s\tremaining: 0us\n",
      "Accuracy: 0.9426011692354415\n"
     ]
    }
   ],
   "source": [
    "X_trainM = X_train[X_train['Gender'] == 1]\n",
    "X_trainF = X_train[X_train['Gender'] == 0]\n",
    "y_trainM = y_train[X_trainM.index]\n",
    "y_trainF = y_train[X_trainF.index]\n",
    "model = CatBoostClassifier(iterations=200, depth=4, learning_rate=0.2, loss_function='Logloss', verbose=100, l2_leaf_reg= 5)\n",
    "X_trainM2, X_valM, y_trainM2, y_valM = train_test_split(X_trainM, y_trainM, test_size=0.2, random_state=42)\n",
    "X_trainF2, X_valF, y_trainF2, y_valF = train_test_split(X_trainF, y_trainF, test_size=0.2, random_state=42)\n",
    "X_trainM2 = pd.concat([X_trainM2, X_trainF])\n",
    "y_trainM2 = pd.concat([y_trainM2, y_trainF])\n",
    "X_trainF2 = pd.concat([X_trainF2, X_trainM])\n",
    "y_trainF2 = pd.concat([y_trainF2, y_trainM])\n",
    "model.fit(X_trainM2, y_trainM2)\n",
    "y_predM = model.predict(X_valM)\n",
    "print('Accuracy for male:', accuracy_score(y_valM, y_predM))\n",
    "model.fit(X_trainF2, y_trainF2)\n",
    "y_predF = model.predict(X_valF)\n",
    "print('Accuracy for female:', accuracy_score(y_valF, y_predF))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predM, y_predF])\n",
    "y_val = np.concatenate([y_valM, y_valF])\n",
    "\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model  = CatBoostClassifier(iterations=200, depth=5, learning_rate=0.1, loss_function='Logloss', verbose=100, l2_leaf_reg= 1)\n",
    "\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for male: 0.943206127941481\n",
      "Accuracy for female: 0.9395831575394481\n",
      "Accuracy combined: 0.9415761901146458\n",
      "Accuracy: 0.9423354339078278\n"
     ]
    }
   ],
   "source": [
    "X_trainM = X_train[X_train['Gender'] == 1]\n",
    "X_trainF = X_train[X_train['Gender'] == 0]\n",
    "y_trainM = y_train[X_trainM.index]\n",
    "y_trainF = y_train[X_trainF.index]\n",
    "model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "X_trainM2, X_valM, y_trainM2, y_valM = train_test_split(X_trainM, y_trainM, test_size=0.2, random_state=42)\n",
    "X_trainF2, X_valF, y_trainF2, y_valF = train_test_split(X_trainF, y_trainF, test_size=0.2, random_state=42)\n",
    "X_trainM2 = pd.concat([X_trainM2, X_trainF])\n",
    "y_trainM2 = pd.concat([y_trainM2, y_trainF])\n",
    "X_trainF2 = pd.concat([X_trainF2, X_trainM])\n",
    "y_trainF2 = pd.concat([y_trainF2, y_trainM])\n",
    "model.fit(X_trainM2, y_trainM2)\n",
    "y_predM = model.predict(X_valM)\n",
    "print('Accuracy for male:', accuracy_score(y_valM, y_predM))\n",
    "model.fit(X_trainF2, y_trainF2)\n",
    "y_predF = model.predict(X_valF)\n",
    "print('Accuracy for female:', accuracy_score(y_valF, y_predF))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predM, y_predF])\n",
    "y_val = np.concatenate([y_valM, y_valF])\n",
    "\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for male: 0.9440342281416051\n",
      "Accuracy for female: 0.9411863977723399\n",
      "Accuracy combined: 0.9427530179940778\n",
      "Accuracy: 0.9421835851491914\n"
     ]
    }
   ],
   "source": [
    "X_trainM = X_train[X_train['Gender'] == 1]\n",
    "X_trainF = X_train[X_train['Gender'] == 0]\n",
    "y_trainM = y_train[X_trainM.index]\n",
    "y_trainF = y_train[X_trainF.index]\n",
    "model = XGBClassifier(colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "X_trainM2, X_valM, y_trainM2, y_valM = train_test_split(X_trainM, y_trainM, test_size=0.2, random_state=42)\n",
    "X_trainF2, X_valF, y_trainF2, y_valF = train_test_split(X_trainF, y_trainF, test_size=0.2, random_state=42)\n",
    "X_trainM2 = pd.concat([X_trainM2, X_trainF])\n",
    "y_trainM2 = pd.concat([y_trainM2, y_trainF])\n",
    "X_trainF2 = pd.concat([X_trainF2, X_trainM])\n",
    "y_trainF2 = pd.concat([y_trainF2, y_trainM])\n",
    "model.fit(X_trainM2, y_trainM2)\n",
    "y_predM = model.predict(X_valM)\n",
    "print('Accuracy for male:', accuracy_score(y_valM, y_predM))\n",
    "model.fit(X_trainF2, y_trainF2)\n",
    "y_predF = model.predict(X_valF)\n",
    "print('Accuracy for female:', accuracy_score(y_valF, y_predF))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predM, y_predF])\n",
    "y_val = np.concatenate([y_valM, y_valF])\n",
    "\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier(colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred = model.predict(X_val)   \n",
    "\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Students: 0.8573994252873564\n",
      "Accuracy for Pro: 0.9688071627996534\n",
      "Accuracy combined: 0.9452585225115785\n",
      "Accuracy: 0.9421835851491914\n"
     ]
    }
   ],
   "source": [
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "X_trainS2, X_valS, y_trainS2, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "X_trainS2 = pd.concat([X_trainS2, X_trainP], axis=0)\n",
    "y_trainS2 = pd.concat([y_trainS2, y_trainP], axis=0)\n",
    "X_trainP2, X_valP, y_trainP2, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "X_trainP2 = pd.concat([X_trainP2, X_trainS], axis=0)\n",
    "y_trainP2 = pd.concat([y_trainP2, y_trainS], axis=0)\n",
    "\n",
    "model = XGBClassifier(colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "\n",
    "model.fit(X_trainS, y_trainS)\n",
    "y_predS = model.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "model.fit(X_trainP, y_trainP)\n",
    "y_predP = model.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "model.fit(X_train2, y_train2)\n",
    "y_pred = model.predict(X_val)\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting\n",
      "0:\tlearn: 0.5748513\ttotal: 3.59ms\tremaining: 715ms\n",
      "100:\tlearn: 0.3347029\ttotal: 290ms\tremaining: 285ms\n",
      "199:\tlearn: 0.3217873\ttotal: 564ms\tremaining: 0us\n",
      "Accuracy for Students: 0.8563218390804598\n",
      "0:\tlearn: 0.3613511\ttotal: 7.84ms\tremaining: 1.56s\n",
      "100:\tlearn: 0.0830565\ttotal: 635ms\tremaining: 623ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.27s\tremaining: 0us\n",
      "Accuracy for Pro: 0.9682295176663137\n",
      "Accuracy combined: 0.9445752030977147\n",
      "Soft Voting\n",
      "0:\tlearn: 0.5748513\ttotal: 2.35ms\tremaining: 467ms\n",
      "100:\tlearn: 0.3347029\ttotal: 251ms\tremaining: 246ms\n",
      "199:\tlearn: 0.3217873\ttotal: 498ms\tremaining: 0us\n",
      "Accuracy for Students: 0.8561422413793104\n",
      "0:\tlearn: 0.3613511\ttotal: 5.28ms\tremaining: 1.05s\n",
      "100:\tlearn: 0.0830565\ttotal: 649ms\tremaining: 637ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.28s\tremaining: 0us\n",
      "Accuracy for Pro: 0.9683257918552036\n",
      "Accuracy combined: 0.9446131652873738\n",
      "stacking\n",
      "0:\tlearn: 0.5748513\ttotal: 3.94ms\tremaining: 785ms\n",
      "100:\tlearn: 0.3347029\ttotal: 267ms\tremaining: 262ms\n",
      "199:\tlearn: 0.3217873\ttotal: 521ms\tremaining: 0us\n",
      "0:\tlearn: 0.5739629\ttotal: 3.15ms\tremaining: 627ms\n",
      "100:\tlearn: 0.3298149\ttotal: 226ms\tremaining: 221ms\n",
      "199:\tlearn: 0.3155578\ttotal: 466ms\tremaining: 0us\n",
      "0:\tlearn: 0.5754955\ttotal: 2.72ms\tremaining: 541ms\n",
      "100:\tlearn: 0.3322605\ttotal: 240ms\tremaining: 235ms\n",
      "199:\tlearn: 0.3174641\ttotal: 466ms\tremaining: 0us\n",
      "0:\tlearn: 0.5749333\ttotal: 2.17ms\tremaining: 433ms\n",
      "100:\tlearn: 0.3296816\ttotal: 227ms\tremaining: 223ms\n",
      "199:\tlearn: 0.3147317\ttotal: 461ms\tremaining: 0us\n",
      "0:\tlearn: 0.5738111\ttotal: 4.22ms\tremaining: 839ms\n",
      "100:\tlearn: 0.3316411\ttotal: 233ms\tremaining: 228ms\n",
      "199:\tlearn: 0.3165358\ttotal: 462ms\tremaining: 0us\n",
      "0:\tlearn: 0.5742581\ttotal: 2.26ms\tremaining: 450ms\n",
      "100:\tlearn: 0.3330357\ttotal: 225ms\tremaining: 221ms\n",
      "199:\tlearn: 0.3180301\ttotal: 455ms\tremaining: 0us\n",
      "Accuracy for Students: 0.8547054597701149\n",
      "0:\tlearn: 0.3613511\ttotal: 7.27ms\tremaining: 1.45s\n",
      "100:\tlearn: 0.0830565\ttotal: 729ms\tremaining: 714ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.47s\tremaining: 0us\n",
      "0:\tlearn: 0.3661154\ttotal: 7.33ms\tremaining: 1.46s\n",
      "100:\tlearn: 0.0826031\ttotal: 610ms\tremaining: 598ms\n",
      "199:\tlearn: 0.0790466\ttotal: 1.23s\tremaining: 0us\n",
      "0:\tlearn: 0.3662836\ttotal: 5.8ms\tremaining: 1.15s\n",
      "100:\tlearn: 0.0827932\ttotal: 632ms\tremaining: 620ms\n",
      "199:\tlearn: 0.0791480\ttotal: 1.23s\tremaining: 0us\n",
      "0:\tlearn: 0.3651914\ttotal: 7.5ms\tremaining: 1.49s\n",
      "100:\tlearn: 0.0818489\ttotal: 583ms\tremaining: 571ms\n",
      "199:\tlearn: 0.0785480\ttotal: 1.17s\tremaining: 0us\n",
      "0:\tlearn: 0.3600526\ttotal: 6.29ms\tremaining: 1.25s\n",
      "100:\tlearn: 0.0827970\ttotal: 599ms\tremaining: 587ms\n",
      "199:\tlearn: 0.0790532\ttotal: 1.18s\tremaining: 0us\n",
      "0:\tlearn: 0.3653934\ttotal: 5.73ms\tremaining: 1.14s\n",
      "100:\tlearn: 0.0832302\ttotal: 591ms\tremaining: 579ms\n",
      "199:\tlearn: 0.0798026\ttotal: 1.16s\tremaining: 0us\n",
      "Accuracy for Pro: 0.9676518725329739\n",
      "Accuracy combined: 0.9437779971148735\n",
      "stacking\n",
      "0:\tlearn: 0.5748513\ttotal: 2.39ms\tremaining: 475ms\n",
      "100:\tlearn: 0.3347029\ttotal: 229ms\tremaining: 224ms\n",
      "199:\tlearn: 0.3217873\ttotal: 459ms\tremaining: 0us\n",
      "0:\tlearn: 0.5739629\ttotal: 1.95ms\tremaining: 389ms\n",
      "100:\tlearn: 0.3298149\ttotal: 205ms\tremaining: 201ms\n",
      "199:\tlearn: 0.3155578\ttotal: 411ms\tremaining: 0us\n",
      "0:\tlearn: 0.5754955\ttotal: 2.07ms\tremaining: 412ms\n",
      "100:\tlearn: 0.3322605\ttotal: 320ms\tremaining: 314ms\n",
      "199:\tlearn: 0.3174641\ttotal: 541ms\tremaining: 0us\n",
      "0:\tlearn: 0.5749333\ttotal: 2.14ms\tremaining: 426ms\n",
      "100:\tlearn: 0.3296816\ttotal: 202ms\tremaining: 198ms\n",
      "199:\tlearn: 0.3147317\ttotal: 406ms\tremaining: 0us\n",
      "0:\tlearn: 0.5738111\ttotal: 2.24ms\tremaining: 446ms\n",
      "100:\tlearn: 0.3316411\ttotal: 206ms\tremaining: 202ms\n",
      "199:\tlearn: 0.3165358\ttotal: 417ms\tremaining: 0us\n",
      "0:\tlearn: 0.5742581\ttotal: 2.06ms\tremaining: 410ms\n",
      "100:\tlearn: 0.3330357\ttotal: 208ms\tremaining: 204ms\n",
      "199:\tlearn: 0.3180301\ttotal: 414ms\tremaining: 0us\n",
      "Accuracy for Students: 0.8552442528735632\n",
      "0:\tlearn: 0.3613511\ttotal: 6.74ms\tremaining: 1.34s\n",
      "100:\tlearn: 0.0830565\ttotal: 639ms\tremaining: 626ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.41s\tremaining: 0us\n",
      "0:\tlearn: 0.3661154\ttotal: 6.18ms\tremaining: 1.23s\n",
      "100:\tlearn: 0.0826031\ttotal: 479ms\tremaining: 469ms\n",
      "199:\tlearn: 0.0790466\ttotal: 957ms\tremaining: 0us\n",
      "0:\tlearn: 0.3662836\ttotal: 5.85ms\tremaining: 1.16s\n",
      "100:\tlearn: 0.0827932\ttotal: 490ms\tremaining: 481ms\n",
      "199:\tlearn: 0.0791480\ttotal: 963ms\tremaining: 0us\n",
      "0:\tlearn: 0.3651914\ttotal: 5.33ms\tremaining: 1.06s\n",
      "100:\tlearn: 0.0818489\ttotal: 480ms\tremaining: 470ms\n",
      "199:\tlearn: 0.0785480\ttotal: 962ms\tremaining: 0us\n",
      "0:\tlearn: 0.3600526\ttotal: 5.2ms\tremaining: 1.03s\n",
      "100:\tlearn: 0.0827970\ttotal: 495ms\tremaining: 485ms\n",
      "199:\tlearn: 0.0790532\ttotal: 1.04s\tremaining: 0us\n",
      "0:\tlearn: 0.3653934\ttotal: 4.44ms\tremaining: 883ms\n",
      "100:\tlearn: 0.0832302\ttotal: 499ms\tremaining: 490ms\n",
      "199:\tlearn: 0.0798026\ttotal: 1.16s\tremaining: 0us\n",
      "Accuracy for Pro: 0.9682776547607587\n",
      "Accuracy combined: 0.9443853921494192\n"
     ]
    }
   ],
   "source": [
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "X_trainS2, X_valS, y_trainS2, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "X_trainS2 = pd.concat([X_trainS2, X_trainP], axis=0)\n",
    "y_trainS2 = pd.concat([y_trainS2, y_trainP], axis=0)\n",
    "X_trainP2, X_valP, y_trainP2, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "X_trainP2 = pd.concat([X_trainP2, X_trainS], axis=0)\n",
    "y_trainP2 = pd.concat([y_trainP2, y_trainS], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Hard Voting\")\n",
    "# model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "vote = VotingClassifier(estimators=estimators, voting='hard')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vote.fit(X_trainS, y_trainS)\n",
    "y_predS = vote.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "vote.fit(X_trainP, y_trainP)\n",
    "y_predP = vote.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "print(\"Soft Voting\")\n",
    "# model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "vote = VotingClassifier(estimators=estimators, voting='soft')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vote.fit(X_trainS, y_trainS)\n",
    "y_predS = vote.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "vote.fit(X_trainP, y_trainP)\n",
    "y_predP = vote.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"stacking\")\n",
    "# model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8))\n",
    "\n",
    "\n",
    "\n",
    "stack.fit(X_trainS, y_trainS)\n",
    "y_predS = stack.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "stack.fit(X_trainP, y_trainP)\n",
    "y_predP = stack.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "print(\"stacking\")\n",
    "# model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator= LogisticRegression(C=100, l1_ratio=None, max_iter=10000, penalty='l1', solver='liblinear'))\n",
    "\n",
    "\n",
    "\n",
    "stack.fit(X_trainS, y_trainS)\n",
    "y_predS = stack.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "stack.fit(X_trainP, y_trainP)\n",
    "y_predP = stack.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Students: 0.8579382183908046\n",
      "Accuracy for Pro: 0.9690478482718783\n",
      "Accuracy combined: 0.9455622200288513\n",
      "Accuracy: 0.9425252448561233\n"
     ]
    }
   ],
   "source": [
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "X_trainS2, X_valS, y_trainS2, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "X_trainS2 = pd.concat([X_trainS2, X_trainP], axis=0)\n",
    "y_trainS2 = pd.concat([y_trainS2, y_trainP], axis=0)\n",
    "X_trainP2, X_valP, y_trainP2, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "X_trainP2 = pd.concat([X_trainP2, X_trainS], axis=0)\n",
    "y_trainP2 = pd.concat([y_trainP2, y_trainS], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model =GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_trainS, y_trainS)\n",
    "y_predS = model.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "model.fit(X_trainP, y_trainP)\n",
    "y_predP = model.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "model.fit(X_train2, y_train2)\n",
    "y_pred = model.predict(X_val)\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5748513\ttotal: 3.96ms\tremaining: 789ms\n",
      "100:\tlearn: 0.3347029\ttotal: 250ms\tremaining: 245ms\n",
      "199:\tlearn: 0.3217873\ttotal: 511ms\tremaining: 0us\n",
      "Accuracy for Students: 0.8611709770114943\n",
      "0:\tlearn: 0.3613511\ttotal: 7.84ms\tremaining: 1.56s\n",
      "100:\tlearn: 0.0830565\ttotal: 748ms\tremaining: 733ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.42s\tremaining: 0us\n",
      "Accuracy for Pro: 0.9689997111774333\n",
      "Accuracy combined: 0.9462075772530559\n",
      "0:\tlearn: 0.4206962\ttotal: 7.31ms\tremaining: 1.45s\n",
      "100:\tlearn: 0.1379309\ttotal: 646ms\tremaining: 633ms\n",
      "199:\tlearn: 0.1341230\ttotal: 1.28s\tremaining: 0us\n",
      "Accuracy: 0.9425632070457824\n"
     ]
    }
   ],
   "source": [
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "X_trainS2, X_valS, y_trainS2, y_valS = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "X_trainS2 = pd.concat([X_trainS2, X_trainP], axis=0)\n",
    "y_trainS2 = pd.concat([y_trainS2, y_trainP], axis=0)\n",
    "X_trainP2, X_valP, y_trainP2, y_valP = train_test_split(X_trainP, y_trainP, test_size=0.2, random_state=42)\n",
    "X_trainP2 = pd.concat([X_trainP2, X_trainS], axis=0)\n",
    "y_trainP2 = pd.concat([y_trainP2, y_trainS], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(iterations=200, depth=4, learning_rate=0.2, loss_function='Logloss', verbose=100, l2_leaf_reg= 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_trainS, y_trainS)\n",
    "y_predS = model.predict(X_valS)\n",
    "print('Accuracy for Students:', accuracy_score(y_valS, y_predS))\n",
    "model.fit(X_trainP, y_trainP)\n",
    "y_predP = model.predict(X_valP)\n",
    "print('Accuracy for Pro:', accuracy_score(y_valP, y_predP))\n",
    "\n",
    "# concatenate the predictions\n",
    "y_pred = np.concatenate([y_predS, y_predP])\n",
    "y_val = np.concatenate([y_valS, y_valP])\n",
    "print('Accuracy combined:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "model.fit(X_train2, y_train2)\n",
    "y_pred = model.predict(X_val)\n",
    "print('Accuracy:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5748513\ttotal: 2.54ms\tremaining: 507ms\n",
      "100:\tlearn: 0.3347029\ttotal: 273ms\tremaining: 267ms\n",
      "199:\tlearn: 0.3217873\ttotal: 542ms\tremaining: 0us\n",
      "0:\tlearn: 0.3613511\ttotal: 7.78ms\tremaining: 1.55s\n",
      "100:\tlearn: 0.0830565\ttotal: 628ms\tremaining: 615ms\n",
      "199:\tlearn: 0.0802820\ttotal: 1.24s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "testS = X_test[X_test['Profession_Student'] == 1]\n",
    "testP = X_test[X_test['Profession_Student'] == 0]\n",
    "testS = testS.drop(['Profession_Student'], axis=1)\n",
    "testP = testP.drop(['Profession_Student'], axis=1)\n",
    "\n",
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "model = CatBoostClassifier(iterations=200, depth=4, learning_rate=0.2, loss_function='Logloss', verbose=100, l2_leaf_reg= 5)\n",
    "\n",
    "model.fit(X_trainS, y_trainS)\n",
    "\n",
    "y_predS = model.predict(testS)\n",
    "\n",
    "model.fit(X_trainP, y_trainP)\n",
    "\n",
    "y_predP = model.predict(testP)\n",
    "\n",
    "# concatenate the predictions in the original order\n",
    "\n",
    "y_pred = np.zeros(len(X_test))\n",
    "y_pred[testS.index] = y_predS\n",
    "y_pred[testP.index] = y_predP\n",
    "\n",
    "submission = pd.DataFrame({'id': test['id'], 'Depression': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "testS = X_test[X_test['Profession_Student'] == 1]\n",
    "testP = X_test[X_test['Profession_Student'] == 0]\n",
    "testS = testS.drop(['Profession_Student'], axis=1)\n",
    "testP = testP.drop(['Profession_Student'], axis=1)\n",
    "\n",
    "X_trainS = X_train[X_train['Profession_Student'] == 1]\n",
    "X_trainP = X_train[X_train['Profession_Student'] == 0]\n",
    "X_trainS = X_trainS.drop(['Profession_Student'], axis=1)\n",
    "X_trainP = X_trainP.drop(['Profession_Student'], axis=1)\n",
    "y_trainS = y_train[X_trainS.index]\n",
    "y_trainP = y_train[X_trainP.index]\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8)\n",
    "\n",
    "model.fit(X_trainS, y_trainS)\n",
    "\n",
    "y_predS = model.predict(testS)\n",
    "\n",
    "model.fit(X_trainP, y_trainP)\n",
    "\n",
    "y_predP = model.predict(testP)\n",
    "\n",
    "# concatenate the predictions in the original order\n",
    "\n",
    "y_pred = np.zeros(len(X_test))\n",
    "y_pred[testS.index] = y_predS\n",
    "y_pred[testP.index] = y_predP\n",
    "\n",
    "submission = pd.DataFrame({'id': test['id'], 'Depression': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('sumissions/submissionGB.csv')\n",
    "sub2 = pd.read_csv('sumissions/submissionCTB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub11 = sub1[~sub1.isin(sub2).all(axis=1)]\n",
    "sub22 = sub2[~sub2.isin(sub1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_id = sub11['id']\n",
    "test_diff = test[test['id'].isin(different_id)]\n",
    "index_diff = test_diff.index\n",
    "X_test_diff = X_test.loc[index_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_diffS = X_test_diff[X_test_diff['Profession_Student'] == 1]\n",
    "X_test_diffP = X_test_diff[X_test_diff['Profession_Student'] == 0]\n",
    "X_test_diffS = X_test_diffS.loc[:, (X_test_diffS != 0).any()]\n",
    "X_test_diffP = X_test_diffP.loc[:, (X_test_diffP != 0).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>Degree_M.Tech</th>\n",
       "      <th>Degree_MA</th>\n",
       "      <th>Degree_MBA</th>\n",
       "      <th>Degree_MBBS</th>\n",
       "      <th>Degree_MCA</th>\n",
       "      <th>Degree_MD</th>\n",
       "      <th>Degree_ME</th>\n",
       "      <th>Degree_MHM</th>\n",
       "      <th>Degree_MSc</th>\n",
       "      <th>Degree_PhD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.00000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.491525</td>\n",
       "      <td>26.208232</td>\n",
       "      <td>7.599540</td>\n",
       "      <td>6.466102</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>6.719128</td>\n",
       "      <td>2.762712</td>\n",
       "      <td>0.479419</td>\n",
       "      <td>2.874092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.014528</td>\n",
       "      <td>0.01937</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>0.041162</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>0.009685</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.021792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500535</td>\n",
       "      <td>4.898011</td>\n",
       "      <td>1.537767</td>\n",
       "      <td>1.897575</td>\n",
       "      <td>0.801175</td>\n",
       "      <td>0.479376</td>\n",
       "      <td>3.826142</td>\n",
       "      <td>1.380117</td>\n",
       "      <td>0.500182</td>\n",
       "      <td>1.334251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168166</td>\n",
       "      <td>0.119798</td>\n",
       "      <td>0.13799</td>\n",
       "      <td>0.187311</td>\n",
       "      <td>0.198906</td>\n",
       "      <td>0.161208</td>\n",
       "      <td>0.098055</td>\n",
       "      <td>0.098055</td>\n",
       "      <td>0.168166</td>\n",
       "      <td>0.146180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.030000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.160000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.910000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender         Age        CGPA  Sleep Duration  Dietary Habits  \\\n",
       "count  413.000000  413.000000  413.000000      413.000000      413.000000   \n",
       "mean     0.491525   26.208232    7.599540        6.466102        0.963680   \n",
       "std      0.500535    4.898011    1.537767        1.897575        0.801175   \n",
       "min      0.000000   18.000000    5.030000        4.000000        0.000000   \n",
       "25%      0.000000   22.000000    6.160000        4.000000        0.000000   \n",
       "50%      0.000000   27.000000    7.530000        7.500000        1.000000   \n",
       "75%      1.000000   30.000000    8.910000        7.500000        2.000000   \n",
       "max      1.000000   34.000000   10.000000        9.000000        2.000000   \n",
       "\n",
       "       Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "count                             413.000000        413.000000   \n",
       "mean                                0.644068          6.719128   \n",
       "std                                 0.479376          3.826142   \n",
       "min                                 0.000000          0.000000   \n",
       "25%                                 0.000000          3.000000   \n",
       "50%                                 1.000000          7.000000   \n",
       "75%                                 1.000000         10.000000   \n",
       "max                                 1.000000         12.000000   \n",
       "\n",
       "       Financial Stress  Family History of Mental Illness    Pressure  ...  \\\n",
       "count        413.000000                        413.000000  413.000000  ...   \n",
       "mean           2.762712                          0.479419    2.874092  ...   \n",
       "std            1.380117                          0.500182    1.334251  ...   \n",
       "min            1.000000                          0.000000    1.000000  ...   \n",
       "25%            2.000000                          0.000000    2.000000  ...   \n",
       "50%            3.000000                          0.000000    3.000000  ...   \n",
       "75%            4.000000                          1.000000    4.000000  ...   \n",
       "max            5.000000                          1.000000    5.000000  ...   \n",
       "\n",
       "       Degree_M.Tech   Degree_MA  Degree_MBA  Degree_MBBS  Degree_MCA  \\\n",
       "count     413.000000  413.000000   413.00000   413.000000  413.000000   \n",
       "mean        0.029056    0.014528     0.01937     0.036320    0.041162   \n",
       "std         0.168166    0.119798     0.13799     0.187311    0.198906   \n",
       "min         0.000000    0.000000     0.00000     0.000000    0.000000   \n",
       "25%         0.000000    0.000000     0.00000     0.000000    0.000000   \n",
       "50%         0.000000    0.000000     0.00000     0.000000    0.000000   \n",
       "75%         0.000000    0.000000     0.00000     0.000000    0.000000   \n",
       "max         1.000000    1.000000     1.00000     1.000000    1.000000   \n",
       "\n",
       "        Degree_MD   Degree_ME  Degree_MHM  Degree_MSc  Degree_PhD  \n",
       "count  413.000000  413.000000  413.000000  413.000000  413.000000  \n",
       "mean     0.026634    0.009685    0.009685    0.029056    0.021792  \n",
       "std      0.161208    0.098055    0.098055    0.168166    0.146180  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_diffS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>Degree_M.Tech</th>\n",
       "      <th>Degree_MA</th>\n",
       "      <th>Degree_MBA</th>\n",
       "      <th>Degree_MBBS</th>\n",
       "      <th>Degree_MCA</th>\n",
       "      <th>Degree_MD</th>\n",
       "      <th>Degree_ME</th>\n",
       "      <th>Degree_MHM</th>\n",
       "      <th>Degree_MSc</th>\n",
       "      <th>Degree_PhD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.576108</td>\n",
       "      <td>25.639692</td>\n",
       "      <td>7.665525</td>\n",
       "      <td>6.136802</td>\n",
       "      <td>0.751445</td>\n",
       "      <td>0.772640</td>\n",
       "      <td>7.262042</td>\n",
       "      <td>3.678227</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>3.666825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.019268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494650</td>\n",
       "      <td>7.635219</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>1.974884</td>\n",
       "      <td>0.744266</td>\n",
       "      <td>0.419532</td>\n",
       "      <td>3.595998</td>\n",
       "      <td>1.346570</td>\n",
       "      <td>0.500481</td>\n",
       "      <td>1.296883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087536</td>\n",
       "      <td>0.150434</td>\n",
       "      <td>0.123312</td>\n",
       "      <td>0.115461</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.150434</td>\n",
       "      <td>0.097773</td>\n",
       "      <td>0.130665</td>\n",
       "      <td>0.137597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.665110</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.665110</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.665110</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.665110</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Gender         Age        CGPA  Sleep Duration  Dietary Habits  \\\n",
       "count  519.000000  519.000000  519.000000      519.000000      519.000000   \n",
       "mean     0.576108   25.639692    7.665525        6.136802        0.751445   \n",
       "std      0.494650    7.635219    0.009433        1.974884        0.744266   \n",
       "min      0.000000   18.000000    7.665110        4.000000        0.000000   \n",
       "25%      0.000000   19.000000    7.665110        4.000000        0.000000   \n",
       "50%      1.000000   23.000000    7.665110        5.500000        1.000000   \n",
       "75%      1.000000   30.000000    7.665110        7.500000        1.000000   \n",
       "max      1.000000   50.000000    7.880000        9.000000        2.000000   \n",
       "\n",
       "       Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
       "count                             519.000000        519.000000   \n",
       "mean                                0.772640          7.262042   \n",
       "std                                 0.419532          3.595998   \n",
       "min                                 0.000000          0.000000   \n",
       "25%                                 1.000000          4.000000   \n",
       "50%                                 1.000000          8.000000   \n",
       "75%                                 1.000000         10.000000   \n",
       "max                                 1.000000         12.000000   \n",
       "\n",
       "       Financial Stress  Family History of Mental Illness    Pressure  ...  \\\n",
       "count        519.000000                        519.000000  519.000000  ...   \n",
       "mean           3.678227                          0.499037    3.666825  ...   \n",
       "std            1.346570                          0.500481    1.296883  ...   \n",
       "min            1.000000                          0.000000    1.000000  ...   \n",
       "25%            3.000000                          0.000000    3.000000  ...   \n",
       "50%            4.000000                          0.000000    4.000000  ...   \n",
       "75%            5.000000                          1.000000    5.000000  ...   \n",
       "max            5.000000                          1.000000    5.000000  ...   \n",
       "\n",
       "       Degree_M.Tech   Degree_MA  Degree_MBA  Degree_MBBS  Degree_MCA  \\\n",
       "count     519.000000  519.000000  519.000000   519.000000  519.000000   \n",
       "mean        0.007707    0.023121    0.015414     0.013487    0.011561   \n",
       "std         0.087536    0.150434    0.123312     0.115461    0.107000   \n",
       "min         0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%         0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "50%         0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "75%         0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "max         1.000000    1.000000    1.000000     1.000000    1.000000   \n",
       "\n",
       "        Degree_MD   Degree_ME  Degree_MHM  Degree_MSc  Degree_PhD  \n",
       "count  519.000000  519.000000  519.000000  519.000000  519.000000  \n",
       "mean     0.011561    0.023121    0.009634    0.017341    0.019268  \n",
       "std      0.107000    0.150434    0.097773    0.130665    0.137597  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 73 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_diffP.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
